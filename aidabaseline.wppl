// ===========================
// Baseline clustering-plus-inference model for AIDA
// Katrin Erk  2018
// 
// Very basic one-class clustering model
// where the cluster is characterized by a fuzzy boundary around the current cluster
// 
//
// start: current cluster = one of the possible entry points
// sample parameters mu and sigma of the fuzzy boundary around the cluster from appropriate Gamma distributions
//
// Probabilistically extend by each additional  unit:
//   Sample boundary from a Gaussian characterized by mu
//   Flip coin: is data point inside or out?
//   Hard condition: groupable unit on correct side of boundary
//   Example: we sampled that the unit is “in”, so its distance to current cluster must be < boundary
//   Additional hard, soft conditions from weighted rules
//   influence probability of the sampled cluster
//
//
// usage:
// webppl aidabaseline.wppl --require webppl-json
// ===========================

//-------------------------------
// Hyperparameters
//-----

// hyperparameters for the parameters mu and sigma of the threshold:
// both mu and sigma are drawn from Gamma distributions
var hyperMuShape = 3.0
var hyperMuScale = 1.0
var hyperSigmaShape = 0.25
var hyperSigmaScale = 1.0

//------------------------------------------------
// Data generated by generate_wppl.py
//------------------------------------------------

var jsonData = json.read('aidagraph.json');


//-------------------------------
// Helper functions
//-----


var getdpDistance = function(index1, index2) {
    if (index1 == index2) {
	return 0.0
    } else {
	return index1 < index2 ? jsonData.unitDistances[index1][index2 - index1 - 1] : jsonData.unitDistances[index2][index1 - index2 - 1]
    }
}

//-------------------------------
// Entities, Events, Statements (EES) data structure for units
//-----

// remove duplicates in an array
var myUnique = function(arr) {
    return reduce(function(index, acc) {
	return arr.indexOf( arr[ index ] ) < index ? acc : [ arr[index ]].concat(acc)
    }, [ ],  _.range(arr.length))
}

// add a second array to a first one while omitting duplicates in the 2nd array
var myAddUnique = function(arr1, arr2) {
    return reduce( function(entry, acc) {
	return arr1.indexOf(entry) > -1 ? acc : [ entry ].concat(acc)
    }, arr1, arr2)
}

// compute an EES structure for a single unit
var unitEES = function(uIndex) {

    // determine all subjects and objects that occur in this unit
    var subjobj = reduce(
	function( stmt, acc) {
	    return [ jsonData.theGraph[stmt].subject, jsonData.theGraph[stmt].object ].concat(acc)
	},
	[ ], (jsonData.units)[uIndex])
    
    return {
	// the list of statements is the list that belongs to this unit
	Statements : (jsonData.units)[ uIndex ],
	// extract all entities and events from the unit:
	// an entity is a subject or object that has an entry in theGraph
	// and whose type is "Entity"
	// Same for events except their type is "Event"
	Entities : myUnique(filter(
	    function(entry) {
		return _.has(jsonData.theGraph, entry) && jsonData.theGraph[entry].type == "Entity"
	    }, subjobj)),
	Events: myUnique(filter(
	    function(entry) {
		return _.has(jsonData.theGraph, entry) && jsonData.theGraph[entry].type == "Event"
	    }, subjobj))
    }
}

// extend an EES by the info from a single unit
var unitExtendEES = function(ees, ees2) {
    return { Statements : myAddUnique(ees.Statements, ees2.Statements),
	     Entities: myAddUnique(ees.Entities, ees2.Entities),
	     Events: myAddUnique(ees.Events, ees2.Events)
	   }
}

//-------------------------------
// Helper functions for logical consistency tests
//-----

// apply a function to all events that are in both ees1 and ees2
var allJointEvents = function(fn, ees1, ees2) {
    map( fn,
	 filter( function(ev) { return ees2.Events.indexOf(ev) > -1 }, ees1.Events))
}

// apply a function to all entities that are in both ees1 and ees2
var allJointEntities = function(fn, ees1, ees2) {
    map( fn,
	 filter( function(ent) { return ees2.Entities.indexOf(ent) > -1 }, ees1.Entities))
}

// apply a function to all statements in ees that match the given data structure
// data structure given as a list of [key, value] pairs
var allStatementsMatching = function(fn, ees, keyValPairs) {
    map( fn, filter(
	function(stmt) {
	    return all( function(kv) { stmt[ kv[0] ] == kv[1] }, keyValPairs)
	},
	map( function(stmtLabel) { return jsonData.theGraph[stmtLabel] }, ees.Statements)))
}

//-------------------------------
// Logical consistency tests
//-----


// one and the same event cannot have more than one type
var testEventTypeConsistency = function(ees1, ees2) {
    // forall joint events in ees1, ees2
    allJointEvents(
	function(ev) {
	    // forall type statements in ees1
	    allStatementsMatching(
		function(typeStmt1) {
		    // forall type statements in ees2 with the subject of typeStmt1
		    allStatementsMatching(
			function(typeStmt2) {
			    
			    // the type (stated in the object) must be the same
			    condition( typeStmt1.object == typeStmt2.object )
			    
			}, ees2, [["predicate", "type"], ["subject", typeStmt1.subject]])
		}, ees1, [ ["predicate", "type"]])
	    }, ees1, ees2)
}

// a conflict attack event can only have one attacker.
// Is that the right formulation, or could we possibly see two
// different entity IDs with the same KB entry?
var testUseYourOwnWeapons = function(ees1, ees2) {
    // forall joint events in ees1, ees2
    allJointEvents(
	function(ev) {
	    // for all conflict attack agents of this event in ees1
	    allStatementsMatching(
		function(agentStmt1) {
		    // for all conflict attack agents of this event in ees2
		    allStatementsMatching(
			function(agentStmt2) {
			    
			    // they should be the same
			    factor( agentStmt1.object == agentStmt2.object ? 0 : -3)
			    
			}, ees2, [["predicate", "Conflict_attack_agent"], ["subject", ev]])
		}, ees1, [["predicate", "Conflict_attack_attacker"], ["subject", ev]])
	}, ees1, ees2)
}

var testAllConsistency = function(ees1, ees2) {
    // this one is symmetric
    testEventTypeConsistency(ees1, ees2)
    // this one has to be done in both directions
    testUseYourOwnWeapons(ees1, ees2)
    testUseYourOwnWeapons(ees2, ees1)
}

//-------------------------------
// Model
// This is one incremental sample for the particle filter
//-----

// ees: entity/event/statement structure for the cluster described by inIndices
// inIndices: list of indices of datapoints that are in the cluster
// candidates: list of indices of datapoints that can potentially be added to the cluster
// startIndex: index of datapoint that is the starting point
// muTau, sigmaTau: parameters of the threshold distribution

var extendCluster = function(ees, inIndices, candidates, startIndex, muTau, sigmaTau) {

    if (candidates.length == 0) {
	// we have considered all candidates, the cluster is finished.
	// this currently returns the indices of the units to include.
	// If it is more convenient to get the entities/events/statements structure,
	// return ees instead. 
	return inIndices;
    } else {
	// consider the next candidate
	var candidate = candidates[0]

	// choose a threshold for it
	var tau = gaussian( { mu : muTau, sigma : sigmaTau } )

	// choose whether it is a member
	var isMember = flip()

	// The candidate needs to be on the right side of threshold tau
	if (isMember) {
	    condition( getdpDistance(startIndex, candidate) < tau)

	    var candidateEES = unitEES(candidate)
	    testAllConsistency(ees, candidateEES)

	    return extendCluster( unitExtendEES(ees, candidateEES), inIndices.concat( [ candidate ] ),
				  candidates.slice(1),
				  startIndex, muTau, sigmaTau)
	} else {
	    condition( getdpDistance( startIndex, candidate) > tau)

	    return extendCluster(ees,inIndices,
				 candidates.slice(1),
				 startIndex, muTau, sigmaTau)
	}
    }
}

var model = function(startIndex) {
    var muTau = gamma({shape : hyperMuShape, scale : hyperMuScale })
    var sigmaTau = gamma( { shape : hyperSigmaShape, scale : hyperSigmaScale })
    
    // cluster initially has only startIndex
    // candidates: range[0:len(units)] minus startIndex
    return extendCluster( unitEES(startIndex), [ startIndex ],
			  filter( function(i) { return i != startIndex }, _.range(jsonData.units.length)),
			  startIndex, muTau, sigmaTau)
}
			  

//-------------------------------
// Inference
//-----

var Experiment = function () {
    var startIndex =  randomInteger(jsonData.units.length)

    display("starting point")
    display(startIndex)
    display(unitEES(startIndex))

    var result = Infer( { method : "SMC", particles : 1000 }, function() {
	return model(startIndex)
    })

    return result;
}

//-------------------------------
// Output generation
//-----

Experiment()
