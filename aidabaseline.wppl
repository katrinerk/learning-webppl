// -----------
// usage:
// webppl aidabaseline.wppl --require webppl-json


// core data structure: cluster.


//------------------------------------------------
// Data generated by generate_wppl.py
//------------------------------------------------

// entries:
// theGraph: characterization of statement and ERE nodes in the graph.
//           mapping from node labels to node structures
// statementProximity: pairwise proximity between statement nodes
//           sparse, hence encoded as a mapping from statement node labels
//           to statement node labels to proximities
// entryPoints: list of entryPoint structures;
//           they are alternative cluster seeds to start from
//           an entry point is a structure that describes a cluster,
//           the core data structure described above
// display("reading aidagraph.json")
var aidaData = json.read('aidagraph.json');
// display("done reading aidagraph.json")

//------------------------------------------------
// General functions
//------------------------------------------------

// remove duplicates in an array
var myUnique = function(arr) {
    return reduce(function(index, acc) {
	return arr.indexOf( arr[ index ] ) < index ? acc : [ arr[index ]].concat(acc)
    }, [ ],  _.range(arr.length))
}

// add a second array to a first one while omitting duplicates in the 2nd array
var myAddUnique = function(arr1, arr2) {
    return reduce( function(entry, acc) {
	return arr1.indexOf(entry) > -1 ? acc : [ entry ].concat(acc)
    }, arr1, arr2)
}

// return all members in array1 that are not in array2
var mySetDiff = function(arr1, arr2) {
    return filter(
	function(entry) {
	    return arr2.indexOf(entry) == -1
	}, arr1)
}

// intersection of two arrays
var myIntersection = function(array1, array2) {
    return filter(
	function(e) {
	    return array2.indexOf(e) > -1
	},
	array1)
}
	

// return array minus all elements that are equal to elt
var myArrayMinusElt = function(somearray, elt) {
    return filter(function(e) { return e != elt }, somearray)
}



//------------------------------------------------
// Coreference handling via unification
//------------------------------------------------


// seqConstraintVar is a sequence of core constraint variables from all entrypoints, without duplicates.
// we need this to determine indices for constraint variables to use in unifiers.
var seqConstraintVar = filter(
    function(entry) {
	// retain only variables, i.e. stuff that doesn't have an (ERE) entry in the graph
	return !(_.has(aidaData.theGraph, entry))
    }, myUnique(
	// remove duplicates in
	// flattened arguments of query constraints
	reduce(
	    function(entryPoint, acc1) {
		return reduce(
		    function(cconstraint, acc2) {
			return [ cconstraint[0], cconstraint[2]].concat(acc2)
		    }, acc1, entryPoint.queryConstraints)
	    }, [ ], aidaData.entrypoints)
    )
)

// returns the index of an ERE or constraint variable
var unifierIndex = function(ere) {
    return _.has(aidaData.theGraph, ere) ? aidaData.theGraph[ere].index : (aidaData.eeLength + seqConstraintVar.indexOf(ere))
}

// returns the unifier of an ERE or constraint variable
var unifierGet = function(ere, unifInfo) {
    return unifInfo[ unifierIndex(ere) ]
}

// true if two EREs or constraint variables have the same unifier
var unifierEquals = function(ere1, ere2, unifInfo) {
    return unifierGet(ere1, unifInfo) == unifierGet(ere2, unifInfo)
}

// unifiable: either they are already in the same equivalence class,
// or one of them is an unbound core variable.
var unifierUnifiable = function(ere1, ere2, unifInfo) {
    return unifierVarUnbound(ere1, unifInfo) ||
	unifierVarUnbound(ere2, unifInfo) ||
	unifierEquals(ere1, ere2, unifInfo)
}

// given two unifiers, decide which becomes the unifier of both and which becomes obsolete.
// returns structure with entries newUnifier, obsoleteUnifier.
var unifierDecideUnifier = function(unifier1, unifier2) {
    return unifier1 < unifier2 ?
	{
	    newUnifier : unifier1,
	    obsoleteUnifier : unifier2
	}
    :
        {
	    newUnifier : unifier2,
	    obsoleteUnifier : unifier1
	}
}
	    

// returns a new unifInfo in which ere1 and ere2 have been unified
var unifierUnify = function(ere1, ere2, unifInfo) {
    var unifier1 = unifierGet(ere1, unifInfo)
    var unifier2 = unifierGet(ere2, unifInfo)

    if (unifier1 == unifier2) {
	return unifInfo
    } else {
	var unifierOrder = unifierDecideUnifier(unifier1, unifier2)
	return map(
	    function(unifier) {
		return unifier == unifierOrder.obsoleteUnifier ? unifierOrder.newUnifier : unifier
	    }, unifInfo)
    }
}

// make an initial unifier that maps each ERE or variable to itself.
var unifierInitial = function() {
    return _.range(aidaData.eeLength + seqConstraintVar.length)
}

// unbound core variable:
// true if coreVar doesn't have an entry in theGraph (so it is a core variable)
// and its unifier is itself
var unifierVarUnbound = function(coreVar, unifInfo) {
    return !(_.has(aidaData.theGraph, coreVar)) && unifierGet(coreVar, unifInfo) == unifierIndex(coreVar)
}

// find candidates for which we have already accepted/rejected duplicates (modulo coref).
// accept/reject them accordingly.
// If we accept one that is a coref-duplicate, we get a bonus.
// returns an updated list of candidates.
var unifierStmtEqual = function(cluster, t1, t2) {
    return t1.predicate == t2.predicate &&
	unifierEquals(t1.subject, t2.subject, cluster.corefUnifier) &&
	unifierEquals(t1.object, t2.object, cluster.corefUnifier)
}

//------------------------------------------------
// Access to the data generated by generate_wppl.py
//------------------------------------------------

// given a graph label, find the matching entry
var aidaEntry = function(label) {
    return aidaData.theGraph[ label ]
}

var aidaIsEre = function(label) {
    return aidaData.theGraph[label].type == "Entity" ||
	aidaData.theGraph[label].type == "Event" ||
	aidaData.theGraph[label].type == "Relation"
}


// find all EREs that are mentioned in a given statement
var aidaEreInStatement = function(statement) {
    // retrieve the entry 
    var statementEntry = aidaEntry(statement)
    
    // return subject and objects for this entry
    // that again have an entry in "theGraph" and have an ERE type
    return myUnique(
	filter(aidaIsEre, map(
		function(role) {
		    return statementEntry[role] },
		["subject", "object"]
	    )
	)
    )
}


// given a list of ERE names and a cluster,
// find the statements adjacent to each ERE,
// keeping only the ones that are not already in the given cluster
// and that have a proximity to the cluster of greater than zero
var aidaCandidatesFromEre = function(cluster, ereList) {
    return filter(
	function(stmt) {
	    return candidateProximity(cluster, stmt) > 0
	}, reduce(
	    function(ere, acc1) {
		return reduce(
		    function(stmt, acc2) {
			return (cluster.considered.indexOf(stmt) > -1 ||
				cluster.candidates.indexOf(stmt) > -1 ||
				acc2.indexOf(stmt) > -1) ?
			    acc2 : acc2.concat( stmt )
		    },
		    acc1, aidaData.theGraph[ere].adjacent)    
	    },
	    [ ], ereList)
    )
}

// return all the statements  from cluster.candidates that fill the
// given query constraint.
var aidaStatementMatchingConstraint = function(queryConstraint, cluster) {    
    return filter(
	function(stmt) {
	    var stmtEntry = aidaEntry(stmt)

	    // match if the predicates are the same,
	    // and the arguments are unifiable, i.e.:
	    // either in the same equivalence class, or an unfilled variable and an ERE
	    return queryConstraint[1] == stmtEntry.predicate &&
		unifierUnifiable(queryConstraint[0], stmtEntry.subject, cluster.corefUnifier) &&
		unifierUnifiable(queryConstraint[2], stmtEntry.object, cluster.corefUnifier)
	    
	}, cluster.candidates)
   
}


//-------------------------------
// Proximity measures
//-----

// read the proximity between two statements off the AIDA graph
var aidaProximity = function(stmt1, stmt2) {
    if (_.has(aidaData.statementProximity, stmt1) && _.has(aidaData.statementProximity[stmt1], stmt2)) {
	// we have an entry for stmt1, and a proximity to stmt2: return that
	return aidaData.statementProximity[stmt1][stmt2]
    } else {
	// display(["proximity do not have stmts", stmt1, stmt2])	
	return 0.0
    }
}


// candidate proximity: how close is the candidate to the cluster?
// cluster: structure as above
// candidate: statement label
var candidateProximity = function(cluster, candidate) {
    return averageProximity(cluster, candidate)
}


// candidate proximity as proximity to a random cluster member
var randomMemberProximity = function(cluster, candidate) {
    var randomMember = uniformDraw(cluster.statements)
    return aidaProximity(randomMember, candidate)
}

// candidate proximity as average proximity:
// 1/clustersize sum_{cluster member i} proximity(i, candidate)
// when proximities are random walk probabilities, this is the probability
// of ending up at candidate when taking a one-step random walk from any cluster member.
var averageProximity = function(cluster, candidate) {
    return sum(
	map(
	    function(stmt) {
		return aidaProximity(stmt, candidate)
	    }, cluster.statements))  / cluster.statements.length
}



//-------------------------------
// Logical consistency
//-----

var objectUniquePredicatesHard = ["hasKBEntry", "type"];
var objectUniquePredicates = [ 'Life.Die_Agent', 'Movement.TransportPerson_Person',
			       'Manufacture.Artifact_Manufacturer', 'Movement.TransportPerson_Origin',
			       'Life.Die_Victim', 'Manufacture.Artifact_Artifact', 'Conflict.Attack_Attacker',
			       'Justice.Convict_Defendant', 'Transaction.TransferOwnership_Thing', 'GeneralAffiliation.APORA_Affiliation',
			       'Life.Die_Instrument', 'Conflict.Attack_Instrument', 'Justice.Appeal_Prosecutor',
			       'Movement.TransportArtifact_Destination', 'Contact.Broadcast_Broadcaster',
			       'Conflict.Attack_Target', 'GeneralAffiliation.Sponsorship_Sponsor', 'Movement.TransportArtifact_Origin',
			       'Justice.Appeal_Defendant', 'Justice.Convict_Adjudicator', 'Movement.TransportArtifact_Artifact',
			       'Transaction.TransferOwnership_Recipient', 'Movement.TransportArtifact_Agent',
			       'OrganizationAffiliation.EmploymentMembership_Organization', 'Transaction.TransferOwnership_Giver',
			       'Transaction.TransferOwnership_Beneficiary', 'GeneralAffiliation.Sponsorship_Entity',
			       'Movement.TransportArtifact_Instrument', 'Movement.TransportPerson_Agent', 'Movement.TransportPerson_Instrument',
			       'GeneralAffiliation.MORE_Affiliation' ];

// object uniqueness with hard constraint:
// if p is an object unique predicate, then
// if e1 p e2 and e1 p e3 then e2 = e3
var constObjectUniqueHard = function(clusterEntries, candidateEntry, cluster) {
    // test for subject uniqueness only if our candidate has a predicate that is subject-unique
    if (objectUniquePredicatesHard.indexOf(candidateEntry.predicate > -1)) {
	map(
	    function(clusterEntry) {
		condition(!(unifierEquals(candidateEntry.subject, clusterEntry.subject, cluster.corefUnifier)) ||
			  candidateEntry.predicate != clusterEntry.predicate ||
			  unifierEquals(candidateEntry.object, clusterEntry.object, cluster.corefUnifier))
	    }, clusterEntries)
    }
}

// object uniqueness, soft constraint:
// if p is an object unique predicate, then
// if e1 p e2 and e1 p e3 then e2 = e3
// This is a soft constraint
var constObjectUnique = function(clusterEntries, candidateEntry, cluster) {
    // test for subject uniqueness only if our candidate has a predicate that is subject-unique
    if (objectUniquePredicates.indexOf(candidateEntry.predicate) > -1) {
	map(
	    function(clusterEntry) {
		factor(!(unifierEquals(candidateEntry.subject, clusterEntry.subject, cluster.corefUnifier)) ||
		       candidateEntry.predicate != clusterEntry.predicate ||
		       unifierEquals(candidateEntry.object, clusterEntry.object, cluster.corefUnifier) ?
		       0 : -3)
	    }, clusterEntries)
    }
}

// do use type statements
var constUseTypes = function(cluster, candidateEntry) {
    factor(candidateEntry.predicate == "type" ? 0.1 : 0)
}

// take confidence into account
var constConfidence = function(cluster, candidateEntry) {
    factor(Math.log(candidateEntry.conf))
}

// a list of all the constraints to apply to pairs of statements.
var pairwiseConstraints = [ constObjectUniqueHard, constObjectUnique ];
// a list of all constraints to apply to the candidate statement
var unaryConstraints = [ constUseTypes, constConfidence ];

// test the logical consistency of the given cluster if candidate was to be added to it
// cluster: structure.
// candidate: statement index
var logicalConsistency = function(cluster, candidate) {
    // map statements to entries
    var candidateEntry = aidaEntry(candidate) 
    var clusterEntries = map(aidaEntry, cluster.statements)

    // apply binary constraints
    map(
	function(constraintFn) {
	    constraintFn(clusterEntries, candidateEntry, cluster)
	}, pairwiseConstraints)

    // and apply unary constraints on the candidat entry
    map(
	function(constraintFn) {
	    constraintFn(cluster, candidateEntry)
	}, unaryConstraints)
}

var stmtIsDuplicate = function(cluster, stmt, stmtSet) {
    return any(
	function(otherEntry) {
	    unifierStmtEqual(cluster, stmt, otherEntry)
	}, stmtSet)
}

var candidateIsNonDuplicate = function(cluster, candidateEntry, memberEntries, nonmemberEntries) {
    if (stmtIsDuplicate(cluster, candidateEntry, memberEntries)) {
	// factor(0.1)
	return false
    } else {
	if (stmtIsDuplicate(cluster, candidateEntry, nonmemberEntries)) {
	    return false
	} else {
	    return true
	}
    }
}


var candidateRemoveDuplicates = function(cluster, candidates) {
    var clusterEntries = map(aidaEntry, cluster.statements)
    var clusterNonEntries = map(aidaEntry, mySetDiff(cluster.considered, cluster.statements))
	
    return filter(
	function(candidate) {
	    return candidateIsNonDuplicate(cluster, aidaEntry(candidate), clusterEntries, clusterNonEntries)
	}, candidates)
}

//-------------------------------
// Functions that check and manipulate cluster objects
//-----

var clusterObjectInit = function(clusterSeed, corefFn) {
    // make a cluster of our internal format
    return {
	// cluster members
	ere : clusterSeed.ere,
	statements : clusterSeed.statements,
	corefStatements : [ ],
	// query (core facets)
	queryConstraints : clusterSeed.queryConstraints,
	queryFailed : [ ],
	// to handle coreference, we carry around a unifier object
	// that records which EREs corefer, as well as a function
	// that shows which coref statements are true
 	corefUnifier: unifierInitial(),
	corefFn : corefFn,
	// statements adjacent to EREs in the cluster for which we have not decided
	// yet whether they should go in
	candidates : [ ],
	// statements for which we have already decided whether they go in the cluster or not
	considered : clusterSeed.statements
    }
}


var clusterNoMoreQueryConstraints = function(cluster) {
    return cluster.queryConstraints.length == 0
}

var clusterNoMoreCandidateStatements = function(cluster) {
    return cluster.candidates.length == 0
}

// compute new cluster when the candidate is added
var clusterAddCandidate = function(cluster, candidate) {
    
    // compute updated cluster components
    var newEre = mySetDiff( aidaEreInStatement(candidate), cluster.ere)
    var updatedStatements = cluster.statements.concat(candidate)
    var updatedConsidered = cluster.considered.concat(candidate)
    var updatedCandidates = myArrayMinusElt(cluster.candidates, candidate)
    
    var clusterUpdated = {
	// cluster members
	ere : cluster.ere.concat(newEre), 
	statements : updatedStatements,
	corefStatements : cluster.corefStatements,
	// query (core facets)
	queryConstraints : cluster.queryConstraints,
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: cluster.corefUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : updatedCandidates,
	// statements for which a decision has been made
	considered : updatedConsidered
    }
	
    return {
	newCluster : clusterUpdated, 
	newERE : newEre,
	newStatements : [ candidate ]
    }
}

// compute new cluster when the candidate is not added
var clusterDropCandidate = function(cluster, candidate) {
    var updatedCandidates = myArrayMinusElt(cluster.candidates, candidate)
    var updatedConsidered = cluster.considered.concat(candidate)

    // display("not adding")
    // display(["cand", updatedCandidates])
    // display(["stmt CAP cand", myIntersection(cluster.statements, updatedCandidates)])

    var updatedCluster = {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements, 
	corefStatements : cluster.corefStatements,
	// query (core facets)
	queryConstraints : cluster.queryConstraints,
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: cluster.corefUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : updatedCandidates,
	// statements for which a decision has been made
	considered : updatedConsidered
    }
    

    // display(["update dropCandidate yields", updated2.candidates])
    
    return {
	newCluster : updatedCluster,
	newERE : [ ],
	newStatements : [ ]
    }
}

// core extension: nothing to do. just remove the candidate from the core constraints
var clusterQueryNothingToDo = function(cluster, queryConstraint) {
    var updatedCluster = {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements, 
	corefStatements : cluster.corefStatements,
	// query (core facets)
	queryConstraints : myArrayMinusElt(cluster.queryConstraints, queryConstraint),
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: cluster.corefUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : cluster.candidates, 
	// statements for which a decision has been made
	considered : cluster.considered 
    }
    
    return {
	newCluster : updatedCluster, 
	newERE : [ ],
	newStatements : [ ]
    }
}

// core extension: could not fulfil query. List it as failed.
var clusterQueryFailed = function(cluster, queryConstraint) {
    var updatedCluster = {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements, 
	corefStatements : cluster.corefStatements,
	// query (core facets)
	queryConstraints : myArrayMinusElt(cluster.queryConstraints, queryConstraint),
	queryFailed : cluster.queryFailed.concat(queryConstraint),
	// coref
 	corefUnifier: cluster.corefUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : cluster.candidates, 
	// statements for which a decision has been made
	considered : cluster.considered 
    }
    
    return {
	newCluster : updatedCluster, 
	newERE : [ ],
	newStatements : [ ]
    }
}



// found a candidate to fill a query constraint. add it
var clusterQueryAdd = function(cluster, queryConstraint, candidate) {
    

    // unify the first argument of the candidate with the first variable in the constraint,
    // and the second argument of the candidate with the second variable in the constraint
    var candidateEntry = aidaEntry(candidate)
    var updatedUnifier1 = unifierUnify(candidateEntry.subject, queryConstraint[0], cluster.corefUnifier)
    var updatedUnifier = unifierUnify(candidateEntry.object, queryConstraint[2], updatedUnifier1)

    var updatedCluster = {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements, 
	corefStatements : cluster.corefStatements,
	// query (core facets)
	queryConstraints : myArrayMinusElt(cluster.queryConstraints, queryConstraint),
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: updatedUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : cluster.candidates, 
	// statements for which a decision has been made
	considered : cluster.considered 
    }
      // display(["updated queryAdd yields", updated2.query])
    
    // the rest is as in clusterAddCandidate, so use that
    return clusterAddCandidate( updatedCluster, candidate)
}


//-------------------------------
// Handling coreference
//-----

// throw a coin to see whether this coref statement should be a  member of the cluster
var corefIsMember = function(cluster, corefStmt) {
    var corefGroup = aidaData.theGraph[corefStmt].cluster
    var member = aidaData.theGraph[corefStmt].clusterMember
    var confidence = aidaData.theGraph[corefStmt].conf

    // coref group not in the cluster yet, and we've sampled that this ere is in the group
    return (cluster.corefFn(corefGroup, member, confidence))   
}

// for all coref statements, decide whether they are true in this sample. 
var corefDo = function(cluster) {
    // returns a structure containing: 
    // newERE, newCluster.

    // decide coreference for all groups
    var corefStmts = filter(
	function(label) {
	    return (aidaData.theGraph[label].type == "ClusterMembership" &&
		    corefIsMember(cluster, label))
	}, _.keys(aidaData.theGraph))

    var corefGroups = myUnique(
	map(
	    function(corefStmt) {
		return aidaData.theGraph[corefStmt].cluster
	    }, corefStmts)
    )

    var newUnifier = reduce(
	function(corefStmt, acc) {
	    var clMember = aidaData.theGraph[corefStmt].clusterMember
	    var corefGroup = aidaData.theGraph[corefStmt].cluster
	    var clPrototype = aidaData.theGraph[ corefGroup ].prototype

	    return unifierUnify(clMember, clPrototype, acc)
	}, cluster.corefUnifier, corefStmts)

    return {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements, 
	corefStatements : corefStmts,
	// query (core facets)
	queryConstraints : cluster.queryConstraints, 
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: newUnifier, 
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : cluster.candidates, 
	// statements for which a decision has been made
	considered : cluster.considered 
    }
}

// determine EREs that are not in the cluster yet but that are
// in the same equivalence groups as the eres in 'eres'
var corefAdditionalEres = function(cluster, eres) {
    return filter(
	function(ere) {
	    return aidaIsEre(ere) &&
		cluster.ere.indexOf(ere) == -1 &&
		any(
		    function(ere2) {
			unifierEquals(ere, ere2, cluster.corefUnifier)
		    }, eres)
	}, _.keys(aidaData.theGraph))
}

//-------------------------------
// Extending the cluster
//-----

// extend the cluster once, either by choosing a core constraint to fill, if there is one,
// or by choosing a statement that we haven't considered yet that is adjacent to one
// of the cluster's EREs
var extendClusterOnce = function(cluster, thresholdParameters) {
    // if there are no query constraints, add a candidate statement from the frontier.
    if (clusterNoMoreQueryConstraints(cluster)) {
	return extendClusterOnceByCandidateStatement(cluster, thresholdParameters)
    } else {
	// we do still have core constraints to do
	return extendClusterOnceByQueryConstraint(cluster, thresholdParameters)
    }
}

// extend the cluster once by choosing a core constraint to fill
// this returns a structure with entries
// newCluster: updated cluster
// newERE: EREs added to the frontier of the cluster
// newStatements: statements added to the cluster
var extendClusterOnceByQueryConstraint = function(cluster, thresholdParameters) {
    if (clusterNoMoreQueryConstraints(cluster)) {
	// nothing to do after all
	return {
	    newCluster : cluster,
	    newERE : [ ],
	    newStatements : [ ]
	}
    } else {
	// query constraints remaining. randomly choose one of them.
	var queryConstraint = uniformDraw(cluster.queryConstraints)
	// display(["considering query constraint", queryConstraint])

	// constraint has the form ?entry1 Rel ?entry2
	var arg1 = queryConstraint[0]
	var arg2 = queryConstraint[2]

	if (!unifierVarUnbound(arg1, cluster.corefUnifier) && !unifierVarUnbound(arg2, cluster.corefUnifier)) {
	    // nothing to do, this query constraint is already fulfilled
	    // display("queryConstraint done")
	    return clusterQueryNothingToDo(cluster, queryConstraint)
	} else {
	    if (unifierVarUnbound(arg1, cluster.corefUnifier) && unifierVarUnbound(arg2, cluster.corefUnifier)) {
		// we cannot possibly fill this constraint at this point.
		// don't fill it, and give this sample a penalty
		// display(["queryConstraint cannot be filled", queryConstraint])
		factor(-5)
		return clusterQueryFailed(cluster, queryConstraint)
	    } else {
		// draw a random statement that can fill this query facet.
		var candidates = aidaStatementMatchingConstraint(queryConstraint, cluster)
		// display(["queryConstraint candidates", candidates])
		if (candidates.length == 0) {
		    // no match for this constraint. just don't fill it then,
		    // and give this sample a penality
		    // display(["queryConstraint cannot be filled", queryConstraint])
		    factor(-5)
		    return clusterQueryFailed(cluster, queryConstraint)
		} else {
		    var candidate = uniformDraw(candidates)
		    // display(["filling query constraint with candidate", candidate])
		    return clusterQueryAdd(cluster, queryConstraint, candidate)
		}
	    }
	}
    }
}

// extend the cluster once by choosing a statement from the candidate list
// this returns a structure with entries
// newCluster: updated cluster
// newERE: EREs added to the frontier of the cluster
// newStatements: statements added to the cluster
var extendClusterOnceByCandidateStatement = function(cluster, thresholdParameters) {
    if (clusterNoMoreCandidateStatements(cluster)) {
	// nothing to do after all
	return {
	    newCluster : cluster,
	    newERE : [ ],
	    newStatements : [ ]
	}
    } else {
	// consider a candidate
	var candidate = uniformDraw(cluster.candidates)
	    
	// choose a threshold for it
	var tau = gamma( thresholdParameters )

	// choose whether it is a member
	var isMember = flip()
	// display(["considering candidate", candidate, isMember, tau, candidateProximity(cluster, candidate),
	//	(isMember && candidateProximity(cluster, candidate) > tau) || (!isMember && candidateProximity(cluster, candidate) < tau)])

    

    	// The candidate needs to be on the right side of threshold tau
    	if (isMember) {
    	    condition( candidateProximity(cluster, candidate) > tau)

    	    return clusterAddCandidate(cluster, candidate)
	    
    	} else {
    	    condition( candidateProximity( cluster, candidate) < tau)
	    
    	    return clusterDropCandidate(cluster, candidate)
    	}
    }
}



//-------------------------------
// Inference
//-----

// Recursive sample for the particle filter
var recursivelyExtendCluster = function(cluster, thresholdParameters) {

    if (clusterNoMoreQueryConstraints(cluster) && clusterNoMoreCandidateStatements(cluster)) {
	// nothing more to add to this cluster, end recursion
	// display(["done with", cluster])
	return cluster;
    } else {
	// try to do one step of additions to the cluster
	// this returns a structure with entries
	// newCluster: updated cluster
	// newERE: EREs added to the frontier of the cluster
	// newStatements: statements added to the cluster
	var result = extendClusterOnce(cluster, thresholdParameters)
	
	// take coreference into account
	var newERE = corefAdditionalEres(result.newCluster, result.newERE)

	// candidates: old candidates plus statements adjacent to the new EREs,
	// minus statements already considered
	var newCandidates = candidateRemoveDuplicates(result.newCluster,
						      aidaCandidatesFromEre(result.newCluster, newERE))


	var cluster1 = {
	    // cluster members
	    ere : result.newCluster.ere.concat(newERE),
	    statements : result.newCluster.statements, 
	    corefStatements : result.newCluster.corefStatements,
	    // query (core facets)
	    queryConstraints : result.newCluster.queryConstraints, 
	    queryFailed : result.newCluster.queryFailed,
	    // coref
 	    corefUnifier: result.newCluster.corefUnifier, 
	    corefFn : result.newCluster.corefFn,
	    // "frontier" statements around current EREs
	    candidates : result.newCluster.candidates.concat(newCandidates),
	    // statements for which a decision has been made
	    considered : result.newCluster.considered 
 	}

	// check logical consistency constraints for the new statements
	map(
	    function(candidate) {
		logicalConsistency(cluster1, candidate)
	    }, result.newStatements
	)

	// and repeat
	return recursivelyExtendCluster( cluster1, thresholdParameters)
    }
}
    


var model = function() {
    // cluster seed:
    // draw from entry points
    var clusterSeed =  uniformDraw(aidaData["entrypoints"])
    // display(["cluster seed", clusterSeed])

    // coreference resolution: we use a mem'ed function
    // to remember which EREs belong to which coref group
    var corefGroupMember = mem(function(corefGroup, ere, confidence) {
	return flip(confidence)
    })

    // from this cluster seed, make a cluster of our internal format
    var cluster0 = clusterObjectInit(clusterSeed, corefGroupMember)

    // compute coref membership throughout
    var cluster1 = corefDo(cluster0)

    // compute additional EREs that are coreferent with the ones in the cluster
    var newEres = corefAdditionalEres(cluster1, cluster1.ere)

    // compute candidates
    var candidates0 = aidaCandidatesFromEre(cluster1, cluster1.ere.concat(newEres))
    // filter candidates: remove the ones that are equal to ones we already have.
    var candidates1 = candidateRemoveDuplicates(cluster1, candidates0)
    
    // assemble initial cluster    
    var clusterInitial = {
	// cluster members
	ere : cluster1.ere.concat(newEres),
	statements : cluster1.statements, 
	corefStatements : cluster1.corefStatements,
	// query (core facets)
	queryConstraints : cluster1.queryConstraints, 
	queryFailed : cluster1.queryFailed,
	// coref
 	corefUnifier: cluster1.corefUnifier,
	corefFn : cluster1.corefFn,
	// "frontier" statements around current EREs
	candidates : candidates1,
	// statements for which a decision has been made
	considered : cluster1.considered 
    }
    
						       
    // now do the work
    var clusterFinal = recursivelyExtendCluster(clusterInitial, aidaData.parameters)

    // and report on results
    return {
	statements : sort(clusterFinal.statements.concat(
	    clusterFinal.corefStatements)),
	failedQueries : clusterFinal.queryFailed
    }
}
			  

var Experiment = function () {
    return Infer( { method : "SMC", particles : 1000 }, model)
}

//-------------------------------
var result = Experiment()

display("Writing results to aidaresult.json")
json.write('aidaresult.json', result);

"AIDA baseline done."
