// -----------
// usage:
// webppl aidabaseline.wppl --require webppl-json


// core data structure: cluster.


//------------------------------------------------
// Data generated by generate_wppl.py
//------------------------------------------------

// entries:
// theGraph: characterization of statement and ERE nodes in the graph.
//           mapping from node labels to node structures
// statementProximity: pairwise proximity between statement nodes
//           sparse, hence encoded as a mapping from statement node labels
//           to statement node labels to proximities
// entryPoints: list of entryPoint structures;
//           they are alternative cluster seeds to start from
//           an entry point is a structure that describes a cluster,
//           the core data structure described above
display("reading aidagraph.json")
var aidaData = json.read('aidagraph.json');
display("done reading aidagraph.json")

//------------------------------------------------
// General functions
//------------------------------------------------

// remove duplicates in an array
var myUnique = function(arr) {
    return reduce(function(index, acc) {
	return arr.indexOf( arr[ index ] ) < index ? acc : [ arr[index ]].concat(acc)
    }, [ ],  _.range(arr.length))
}

// add a second array to a first one while omitting duplicates in the 2nd array
var myAddUnique = function(arr1, arr2) {
    return reduce( function(entry, acc) {
	return arr1.indexOf(entry) > -1 ? acc : [ entry ].concat(acc)
    }, arr1, arr2)
}

// return all members in array1 that are not in array2
var mySetDiff = function(arr1, arr2) {
    return filter(
	function(entry) {
	    return arr2.indexOf(entry) == -1
	}, arr1)
}

// intersection of two arrays
var myIntersection = function(array1, array2) {
    return filter(
	function(e) {
	    return array2.indexOf(e) > -1
	},
	array1)
}
	

// return array minus all elements that are equal to elt
var myArrayMinusElt = function(somearray, elt) {
    return filter(function(e) { return e != elt }, somearray)
}



//------------------------------------------------
// Coreference handling via unification
//------------------------------------------------


// seqOfEres a list of all entities and events (no relations, they do not appear in clusters), along with variables that appear in entry points.
// all the unification functions below use the order of EREs and variables in this list
// as a basis for the unifiers they compute.
// seqConstraintVar is a sequence of core constraint variables from all entrypoints, without duplicates
var seqConstraintVar = filter(
    function(entry) {
	// retain only variables, i.e. stuff that doesn't have an (ERE) entry in the graph
	return !(_.has(aidaData.theGraph, entry))
    }, myUnique(
	// remove duplicates in
	// flattened arguments of query constraints
	reduce(
	    function(entryPoint, acc1) {
		return reduce(
		    function(cconstraint, acc2) {
			return [ cconstraint[0], cconstraint[2]].concat(acc2)
		    }, acc1, entryPoint.queryConstraints)
	    }, [ ], aidaData.entrypoints)
    )
)

var seqOfEres = filter(
    function(k) {
	return aidaData.theGraph[k].type == "Event" ||
	    aidaData.theGraph[k].type == "Entity"
    }, _.keys(aidaData.theGraph)).concat(seqConstraintVar)

// returns the unifier of an ERE or constraint variable
var unifierGet = function(ere, unifInfo) {
    return unifInfo[ seqOfEres.indexOf(ere) ]
}

// true if two EREs or constraint variables have the same unifier
var unifierEquals = function(ere1, ere2, unifInfo) {
    return unifierGet(ere1, unifInfo) == unifierGet(ere2, unifInfo)
}

// unifiable: either they are already in the same equivalence class,
// or one of them is an unbound core variable.
var unifierUnifiable = function(ere1, ere2, unifInfo) {
    return unifierVarUnbound(ere1, unifInfo) ||
	unifierVarUnbound(ere2, unifInfo) ||
	unifierEquals(ere1, ere2, unifInfo)
}

// given two unifiers, decide which becomes the unifier of both and which becomes obsolete.
// returns structure with entries newUnifier, obsoleteUnifier.
// see to it that query variables don't become unifiers.
var unifierDecideUnifier = function(unifier1, unifier2) {
    if (unifier1[0] == "?") {
	return {
	    newUnifier : unifier2,
	    obsoleteUnifier : unifier1
	}
    } else {
	if (unifier2[0] == "?") {
	    return {
		newUnifier : unifier1,
		obsoleteUnifier : unifier2
	    }
	} else {
	    return {
		newUnifier : sort([unifier1, unifier2])[0],
		obsoleteUnifier : sort([unifier1, unifier2])[1]
	    }
	}
    }
}	
	    

// returns a new unifInfo in which ere1 and ere2 have been unified
var unifierUnify = function(ere1, ere2, unifInfo) {
    var unifier1 = unifierGet(ere1, unifInfo)
    var unifier2 = unifierGet(ere2, unifInfo)

    if (unifier1 == unifier2) {
	return unifInfo
    } else {
	var unifierOrder = unifierDecideUnifier(unifier1, unifier2)
	return map(
	    function(unifier) {
		return unifier == unifierOrder.obsoleteUnifier ? unifierOrder.newUnifier : unifier
	    }, unifInfo)
    }
}

// make an initial unifier that maps each ERE or variable to itself.
var unifierInitial = function() {
    return seqOfEres
}

// unbound core variable:
// true if coreVar doesn't have an entry in theGraph (so it is a core variable)
// and its unifier is itself
var unifierVarUnbound = function(coreVar, unifInfo) {
    return !(_.has(aidaData.theGraph, coreVar)) && unifierGet(coreVar, unifInfo) == coreVar
}


//------------------------------------------------
// Access to the data generated by generate_wppl.py
//------------------------------------------------

// given a graph label, find the matching entry
var aidaEntry = function(label) {
    return aidaData.theGraph[ label ]
}

// read the proximity between two statements off the AIDA graph
var aidaProximity = function(stmt1, stmt2) {
    if (_.has(aidaData.statementProximity, stmt1) && _.has(aidaData.statementProximity[stmt1], stmt2)) {
	// we have an entry for stmt1, and a proximity to stmt2: return that
	return aidaData.statementProximity[stmt1][stmt2]
    } else {
	return 0.0
    }
}


// take a list of statements and map them to a list of statement entries
var aidaStatementEntries = function(stmtList) {
    return map(
	function(stmt) {
	    return aidaEntry(stmt)
	},
	stmtList)
}


// find all EREs that are mentioned in a given statement
var aidaEreInStatement = function(statement) {
    // retrieve the entry 
    var statementEntry = aidaEntry(statement)
    
    // return subject and objects for this entry
    // that again have an entry in "theGraph" and have an ERE type
    return myUnique(
	filter(
	    function(entry) {
		return _.has(aidaData.theGraph, entry) &&
		    (aidaData.theGraph[entry].type == "Entity" ||
		     aidaData.theGraph[entry].type == "Event" ||
		     aidaData.theGraph[entry].type == "Relation")
	    },
	    map(
		function(role) {
		    return statementEntry[role] },
		["subject", "object"]
	    )
	)
    )
}


// given a list of ERE names and a list of statements,
// find the statements adjacent to each ERE,
// keeping only the ones that are not already in the given cluster
var aidaCandidatesFromEre = function(cluster, ereList) {
    return reduce(
	function(ere, acc1) {
	    return reduce(
		function(stmt, acc2) {
		    return (cluster.considered.indexOf(stmt) > -1 ||
			    cluster.candidates.indexOf(stmt) > -1 ||
			    acc2.indexOf(stmt) > -1) ?
			acc2 : acc2.concat( stmt )
		},
		acc1, aidaData.theGraph[ere].adjacent)    
	},
	[ ], ereList)
}

// get statement triple: given statement index,
// find the statement in theGraph that matches it,
// and transform {subject: A, predicate: B, object:C } to [ A, B, C]
var aidaStatementTriple = function(stmt) {
    var stmtEntry = aidaEntry(stmt)
    return [ stmtEntry.subject, stmtEntry.predicate, stmtEntry.object ]
}

// return all the statements  from cluster.candidates that fill the
// given query constraint.
var aidaStatementMatchingConstraint = function(queryConstraint, cluster) {    
    return filter(
	function(stmt) {
	    var stmtTriple = aidaStatementTriple(stmt)

	    // match if the predicates are the same,
	    // and the arguments are unifiable, i.e.:
	    // either in the same equivalence class, or an unfilled variable and an ERE
	    return queryConstraint[1] == stmtTriple[1] &&
		unifierUnifiable(queryConstraint[0], stmtTriple[0], cluster.coref.unifier) &&
		unifierUnifiable(queryConstraint[2], stmtTriple[2], cluster.coref.unifier)
	    
	}, cluster.candidates)
   
}


//-------------------------------
// Proximity measures
//-----

// candidate proximity: how close is the candidate to the cluster?
// cluster: structure as above
// candidate: statement label
var candidateProximity = function(cluster, candidate) {
    return averageProximity(cluster, candidate)
}


// candidate proximity as proximity to a random cluster member
var randomMemberProximity = function(cluster, candidate) {
    var randomMember = uniformDraw(cluster.cluster.statements)
    return aidaProximity(randomMember, candidate)
}

// candidate proximity as average proximity:
// 1/clustersize sum_{cluster member i} proximity(i, candidate)
// when proximities are random walk probabilities, this is the probability
// of ending up at candidate when taking a one-step random walk from any cluster member.
var averageProximity = function(cluster, candidate) {
    return sum(
	map(
	    function(stmt) {
		return aidaProximity(stmt, candidate)
	    }, cluster.cluster.statements))  / cluster.cluster.statements.length
}



//-------------------------------
// Logical consistency
//-----

var objectUniquePredicatesHard = ["hasKBEntry", "type"];
var objectUniquePredicates = [ 'Life.Die_Agent', 'Movement.TransportPerson_Person',
			       'Manufacture.Artifact_Manufacturer', 'Movement.TransportPerson_Origin',
			       'Life.Die_Victim', 'Manufacture.Artifact_Artifact', 'Conflict.Attack_Attacker',
			       'Justice.Convict_Defendant', 'Transaction.TransferOwnership_Thing', 'GeneralAffiliation.APORA_Affiliation',
			       'Life.Die_Instrument', 'Conflict.Attack_Instrument', 'Justice.Appeal_Prosecutor',
			       'Movement.TransportArtifact_Destination', 'Contact.Broadcast_Broadcaster',
			       'Conflict.Attack_Target', 'GeneralAffiliation.Sponsorship_Sponsor', 'Movement.TransportArtifact_Origin',
			       'Justice.Appeal_Defendant', 'Justice.Convict_Adjudicator', 'Movement.TransportArtifact_Artifact',
			       'Transaction.TransferOwnership_Recipient', 'Movement.TransportArtifact_Agent',
			       'OrganizationAffiliation.EmploymentMembership_Organization', 'Transaction.TransferOwnership_Giver',
			       'Transaction.TransferOwnership_Beneficiary', 'GeneralAffiliation.Sponsorship_Entity',
			       'Movement.TransportArtifact_Instrument', 'Movement.TransportPerson_Agent', 'Movement.TransportPerson_Instrument',
			       'GeneralAffiliation.MORE_Affiliation' ];

// object uniqueness with hard constraint:
// if p is an object unique predicate, then
// if e1 p e2 and e1 p e3 then e2 = e3
var constObjectUniqueHard = function(clusterTriples, candidateTriple, cluster) {
    // test for subject uniqueness only if our candidate has a predicate that is subject-unique
    if (objectUniquePredicatesHard.indexOf(candidateTriple[1]) > -1) {
	map(
	    function(clusterTriple) {
		condition(!(unifierEquals(candidateTriple[0], clusterTriple[0], cluster.coref.unifier)) ||
			  candidateTriple[1] != clusterTriple[1] ||
			  unifierEquals(candidateTriple[2], clusterTriple[2], cluster.coref.unifier))
	    }, clusterTriples)
    }
}

// object uniqueness, soft constraint:
// if p is an object unique predicate, then
// if e1 p e2 and e1 p e3 then e2 = e3
// This is a soft constraint
var constObjectUnique = function(clusterTriples, candidateTriple, cluster) {
    // test for subject uniqueness only if our candidate has a predicate that is subject-unique
    if (objectUniquePredicates.indexOf(candidateTriple[1]) > -1) {
	map(
	    function(clusterTriple) {
		factor(!(unifierEquals(candidateTriple[0], clusterTriple[0], cluster.coref.unifier)) ||
		       candidateTriple[1] != clusterTriple[1] ||
		       unifierEquals(candidateTriple[2], clusterTriple[2], cluster.coref.unifier) ?
		       0 : -3)
	    }, clusterTriples)
    }
}

// do use type statements
var constUseTypes = function(cluster, candidateEntry) {
    factor(candidateEntry.predicate == "type" ? 0.1 : 0)
}

// take confidence into account
var constConfidence = function(cluster, candidateEntry) {
    factor(Math.log(candidateEntry.conf))
}

// a list of all the constraints to apply to pairs of statement triples.
var pairwiseConstraints = [ constObjectUniqueHard, constObjectUnique ];
// a list of all constraints to apply to the candidate statement
var unaryConstraints = [ constUseTypes, constConfidence ];

// test the logical consistency of the given cluster if candidate was to be added to it
// cluster: structure.
// candidate: statement index
var logicalConsistency = function(cluster, candidate) {
    // map statements to triples
    var candidateTriple = aidaStatementTriple(candidate)
    var clusterTriples = map(
	function(i) {
	    return aidaStatementTriple(i)
	}, cluster.cluster.statements)

    // apply binary constraints on triples
    map(
	function(constraintFn) {
	    constraintFn(clusterTriples, candidateTriple, cluster)
	}, pairwiseConstraints)

    // and apply unary constraints on the candidat entry
    var candidateEntry = aidaEntry(candidate)
    map(
	function(constraintFn) {
	    constraintFn(cluster, candidateEntry)
	}, unaryConstraints)
}

// find candidates for which we have already accepted/rejected duplicates (modulo coref).
// accept/reject them accordingly.
// If we accept one that is a coref-duplicate, we get a bonus.
// returns an updated list of candidates.
var tripleEqualModuloUnif = function(cluster, t1, t2) {
    return t1[1] == t2[1] &&
	unifierEquals(t1[0], t2[0], cluster.coref.unifier) &&
	unifierEquals(t1[2], t2[2], cluster.coref.unifier)
}

var tripleInTripleSet = function(cluster, triple, tripleSet) {
    return any(
	function(otherTriple) {
	    tripleEqualModuloUnif(cluster, triple, otherTriple)
	}, tripleSet)
}

var candidateIsNonDuplicate = function(cluster, candidate, clusterTriples, nonClusterTriples) {
    var candidateTriple = aidaStatementTriple(candidate)

    if (tripleInTripleSet(cluster, candidateTriple, clusterTriples)) {
	factor(0.1)
	return false
    } else {
	if (tripleInTripleSet(cluster, candidateTriple, nonClusterTriples)) {
	    return false
	} else {
	    return true
	}
    }
}


var candidateRemoveDuplicates = function(cluster, candidates) {
    var clusterTriples = map(
	function(i) {
	    return aidaStatementTriple(i)
	}, cluster.cluster.statements)

    var nonClusterTriples = map(
	function(i) {
	    return aidaStatementTriple(i)
	}, mySetDiff(cluster.considered, cluster.cluster.statements))

    return filter(
	function(c) {
	    return candidateIsNonDuplicate(cluster, c, clusterTriples, nonClusterTriples)
	}, candidates)
}

//-------------------------------
// Functions that check and manipulate cluster objects
//-----

var clusterObjectInit = function(clusterSeed, corefFn) {
    // make a cluster of our internal format
    return {
	// cluster members
	cluster : {
	    ere : clusterSeed.ere,
	    statements : clusterSeed.statements,
	    corefStatements : [ ],
	    corefGroups : [ ]
	},
	// queries to be fulfilled
	query : {
	    constraints : clusterSeed.queryConstraints,
	    failed : [ ]
	},
	// to handle coreference, we carry around a unifier object
	// that records which EREs corefer, as well as a function
	// that shows which coref statements are true
 	coref: {
	    unifier : unifierInitial(),
	    corefGroupMember : corefFn
	},
	// statements adjacent to EREs in the cluster for which we have not decided
	// yet whether they should go in
	candidates : [ ],
	// statements for which we have already decided whether they go in the cluster or not
	considered : clusterSeed.statements
    }
}

var clusterObjectUpdateCluster = function(cluster, ere, statements, corefStatements, corefGroups) {
    return {
	cluster : {
	    ere : ere,
	    statements : statements,
	    corefStatements : corefStatements,
	    corefGroups : corefGroups
	},
	query : cluster.query,
	coref : cluster.coref,
	candidates : cluster.candidates,
	considered : cluster.considered
    }
}

var clusterObjectUpdateQuery = function(cluster, queryConstraints, failedConstraints) {
    return {
	cluster : cluster.cluster,
	query : {
	    constraints : queryConstraints,
	    failed : failedConstraints
	},
	coref : cluster.coref,
	candidates : cluster.candidates,
	considered : cluster.considered
    }	
}

var clusterObjectUpdateCoref = function(cluster, unifier, corefFn) {
    return {
	cluster : cluster.cluster,
	query : cluster.query,
	coref : {
	    unifier : unifier,
	    corefGroupMember : corefFn
	},
	candidates : cluster.candidates,
	considered : cluster.considered
    }
}

var clusterObjectUpdateCandidates = function(cluster, candidates) {
    return {
	cluster : cluster.cluster,
	query : cluster.query,
	coref : cluster.coref,
	candidates : candidates,
	considered : cluster.considered
    }
}

var clusterObjectUpdateConsidered = function(cluster, considered) {
    return {
	cluster : cluster.cluster,
	query : cluster.query,
	coref : cluster.coref,
	candidates : cluster.candidates,
	considered : considered
    }
}

var clusterNoMoreQueryConstraints = function(cluster) {
    return cluster.query.constraints.length == 0
}

var clusterNoMoreCandidateStatements = function(cluster) {
    return cluster.candidates.length == 0
}

// compute new cluster when the candidate is added
var clusterAddCandidate = function(cluster, candidate) {
    
    // compute updated cluster components
    var newEre = mySetDiff( aidaEreInStatement(candidate), cluster.cluster.ere)
    var updatedStatements = cluster.cluster.statements.concat(candidate)
    var updatedConsidered = cluster.considered.concat(candidate)
    var updatedCandidates = myArrayMinusElt(cluster.candidates, candidate)
    
    // candidates: will be done later.

    var updated1 = clusterObjectUpdateCluster(cluster,
					      cluster.cluster.ere.concat( newEre ),
					      updatedStatements,
					      cluster.cluster.corefStatements,
					      cluster.cluster.corefGroups)
    var updated2 = clusterObjectUpdateConsidered(updated1, updatedConsidered)
    var updated3 = clusterObjectUpdateCandidates(updated2, updatedCandidates)

    // display(["updated: addCandidate yields", updated3.cluster.ere, updated3.cluster.statements])
    
    return {
	newCluster : updated3, 
	newERE : newEre,
	newStatements : [ candidate ]
    }
}

// compute new cluster when the candidate is not added
var clusterDropCandidate = function(cluster, candidate) {
    var updatedCandidates = myArrayMinusElt(cluster.candidates, candidate)
    var updatedConsidered = cluster.considered.concat(candidate)

    // display("not adding")
    // display(["cand", updatedCandidates])
    // display(["stmt CAP cand", myIntersection(cluster.statements, updatedCandidates)])

    var updated1 = clusterObjectUpdateCandidates(cluster, updatedCandidates)
    var updated2 = clusterObjectUpdateConsidered(updated1, updatedConsidered)

    // display(["update dropCandidate yields", updated2.candidates])
    
    return {
	newCluster : updated2, 
	newERE : [ ],
	newStatements : [ ]
    }
}

// core extension: nothing to do. just remove the candidate from the core constraints
var clusterQueryNothingToDo = function(cluster, queryConstraint) {
    var updatedQueryConstraints = myArrayMinusElt(cluster.query.constraints, queryConstraint)
    
    return {
	newCluster : clusterObjectUpdateQuery(cluster, updatedQueryConstraints, cluster.query.failed),
	newERE : [ ],
	newStatements : [ ]
    }
}

// core extension: could not fulfil query. List it as failed.
var clusterQueryFailed = function(cluster, queryConstraint) {
    var updatedQueryConstraints = myArrayMinusElt(cluster.query.constraints, queryConstraint)
    
    return {
	newCluster : clusterObjectUpdateQuery(cluster, updatedQueryConstraints, cluster.query.failed.concat(queryConstraint)),
	newERE : [ ],
	newStatements : [ ]
    }
}



// found a candidate to fill a query constraint. add it
var clusterQueryAdd = function(cluster, queryConstraint, candidate) {
    
    // omit the query constraint we just fulfilled
    var updatedQueryConstraints = myArrayMinusElt(cluster.query.constraints, queryConstraint)

    // unify the first argument of the candidate with the first variable in the constraint,
    // and the second argument of the candidate with the second variable in the constraint
    var candidateTriple = aidaStatementTriple(candidate)
    var updatedUnifier1 = unifierUnify(candidateTriple[0], queryConstraint[0], cluster.coref.unifier)
    var updatedUnifier = unifierUnify(candidateTriple[2], queryConstraint[2], updatedUnifier1)

    var updated1 = clusterObjectUpdateQuery(cluster, updatedQueryConstraints, cluster.query.failed)
    var updated2 = clusterObjectUpdateCoref(updated1, updatedUnifier, cluster.coref.corefGroupMember)

    // display(["updated queryAdd yields", updated2.query])
    
    // the rest is as in clusterAddCandidate, so use that
    return clusterAddCandidate( updated2, candidate)
}


//-------------------------------
// Handling coreference
//-----

// throw a coin to see whether this coref statement should be a  member of the cluster
var corefIsMember = function(cluster, corefStmt) {
    var corefGroup = aidaData.theGraph[corefStmt].cluster
    var member = aidaData.theGraph[corefStmt].clusterMember
    var confidence = aidaData.theGraph[corefStmt].conf

    // coref group not in the cluster yet, and we've sampled that this ere is in the group
    return (cluster.coref.corefGroupMember(corefGroup, member, confidence))   
}

// for all coref statements, decide whether they are true in this sample. 
var corefDo = function(cluster) {
    // returns a structure containing: 
    // newERE, newCluster.

    // decide coreference for all groups
    var corefStmts = filter(
	function(label) {
	    return (aidaData.theGraph[label].type == "ClusterMembership" &&
		    corefIsMember(cluster, label))
	}, _.keys(aidaData.theGraph))

    var corefGroups = myUnique(
	map(
	    function(corefStmt) {
		return aidaData.theGraph[corefStmt].cluster
	    }, corefStmts)
    )

    var cluster1 = clusterObjectUpdateCluster(cluster,
					      cluster.cluster.ere, 
					      cluster.cluster.statements,
					      corefStmts, corefGroups)

    var newUnifier = reduce(
	function(corefStmt, acc) {
	    var clMember = aidaData.theGraph[corefStmt].clusterMember
	    var corefGroup = aidaData.theGraph[corefStmt].cluster
	    var clPrototype = aidaData.theGraph[ corefGroup ].prototype

	    return unifierUnify(clMember, clPrototype, acc)
	}, cluster1.coref.unifier, corefStmts)

    var cluster2 = clusterObjectUpdateCoref(cluster1,
					    newUnifier,
					    cluster1.coref.corefGroupMember)
    

    return cluster2
}

// determine EREs that are not in the cluster yet but that are
// in the same equivalence groups as the eres in 'eres'
var corefAdditionalEres = function(cluster, eres) {
    return filter(
	function(ere) {
	    return _.has(aidaData.theGraph, ere) &&
		cluster.cluster.ere.indexOf(ere) == -1 &&
		any(
		    function(ere2) {
			unifierEquals(ere, ere2, cluster.coref.unifier)
		    }, eres)
	}, seqOfEres)
}

//-------------------------------
// Extending the cluster
//-----

// extend the cluster once, either by choosing a core constraint to fill, if there is one,
// or by choosing a statement that we haven't considered yet that is adjacent to one
// of the cluster's EREs
var extendClusterOnce = function(cluster, thresholdParameters) {
    // if there are no query constraints, add a candidate statement from the frontier.
    if (clusterNoMoreQueryConstraints(cluster)) {
	return extendClusterOnceByCandidateStatement(cluster, thresholdParameters)
    } else {
	// we do still have core constraints to do
	return extendClusterOnceByQueryConstraint(cluster, thresholdParameters)
    }
}

// extend the cluster once by choosing a core constraint to fill
// this returns a structure with entries
// newCluster: updated cluster
// newERE: EREs added to the frontier of the cluster
// newStatements: statements added to the cluster
var extendClusterOnceByQueryConstraint = function(cluster, thresholdParameters) {
    if (clusterNoMoreQueryConstraints(cluster)) {
	// nothing to do after all
	return {
	    newCluster : cluster,
	    newERE : [ ],
	    newStatements : [ ]
	}
    } else {
	// query constraints remaining. randomly choose one of them.
	var queryConstraint = uniformDraw(cluster.query.constraints)
	// display(["considering query constraint", queryConstraint])

	// constraint has the form ?entry1 Rel ?entry2
	var arg1 = queryConstraint[0]
	var arg2 = queryConstraint[2]

	if (!unifierVarUnbound(arg1, cluster.coref.unifier) && !unifierVarUnbound(arg2, cluster.coref.unifier)) {
	    // nothing to do, this query constraint is already fulfilled
	    // display("queryConstraint done")
	    return clusterQueryNothingToDo(cluster, queryConstraint)
	} else {
	    if (unifierVarUnbound(arg1, cluster.coref.unifier) && unifierVarUnbound(arg2, cluster.coref.unifier)) {
		// we cannot possibly fill this constraint at this point.
		// don't fill it, and give this sample a penalty
		// display(["queryConstraint cannot be filled", queryConstraint])
		factor(-5)
		return clusterQueryFailed(cluster, queryConstraint)
	    } else {
		// draw a random statement that can fill this query facet.
		var candidates = aidaStatementMatchingConstraint(queryConstraint, cluster)
		// display(["queryConstraint candidates", candidates])
		if (candidates.length == 0) {
		    // no match for this constraint. just don't fill it then,
		    // and give this sample a penality
		    // display(["queryConstraint cannot be filled", queryConstraint])
		    factor(-5)
		    return clusterQueryFailed(cluster, queryConstraint)
		} else {
		    var candidate = uniformDraw(candidates)
		    // display(["filling query constraint with candidate", candidate])
		    return clusterQueryAdd(cluster, queryConstraint, candidate)
		}
	    }
	}
    }
}

// extend the cluster once by choosing a statement from the candidate list
// this returns a structure with entries
// newCluster: updated cluster
// newERE: EREs added to the frontier of the cluster
// newStatements: statements added to the cluster
var extendClusterOnceByCandidateStatement = function(cluster, thresholdParameters) {
    if (clusterNoMoreCandidateStatements(cluster)) {
	// nothing to do after all
	return {
	    newCluster : cluster,
	    newERE : [ ],
	    newStatements : [ ]
	}
    } else {
	// consider a candidate
	var candidate = uniformDraw(cluster.candidates)
	    
	// choose a threshold for it
	var tau = gamma( thresholdParameters )

	// choose whether it is a member
	var isMember = flip()
	// display(["considering candidate", candidate, isMember, tau, candidateProximity(cluster, candidate)])

    

    	// The candidate needs to be on the right side of threshold tau
    	if (isMember) {
    	    condition( candidateProximity(cluster, candidate) > tau)

    	    return clusterAddCandidate(cluster, candidate)
	    
    	} else {
    	    condition( candidateProximity( cluster, candidate) < tau)
	    
    	    return clusterDropCandidate(cluster, candidate)
    	}
    }
}



//-------------------------------
// Inference
//-----

// Recursive sample for the particle filter
var recursivelyExtendCluster = function(cluster, thresholdParameters) {

    if (clusterNoMoreQueryConstraints(cluster) && clusterNoMoreCandidateStatements(cluster)) {
	// nothing more to add to this cluster, end recursion
	// display(["done with", cluster])
	return cluster;
    } else {
	// try to do one step of additions to the cluster
	// this returns a structure with entries
	// newCluster: updated cluster
	// newERE: EREs added to the frontier of the cluster
	// newStatements: statements added to the cluster
	var result = extendClusterOnce(cluster, thresholdParameters)
	
	// take coreference into account
	var newERE = corefAdditionalEres(result.newCluster, result.newERE)

	// candidates: old candidates plus statements adjacent to the new EREs,
	// minus statements already considered
	var newCandidates = candidateRemoveDuplicates(result.newCluster,
						      aidaCandidatesFromEre(result.newCluster, newERE))


	var cluster1 = clusterObjectUpdateCluster(result.newCluster,
						  result.newCluster.cluster.ere.concat(newERE),
						  result.newCluster.cluster.statements,
						  result.newCluster.cluster.corefStatements,
						  result.newCluster.cluster.corefGroups)

	var cluster2 = clusterObjectUpdateCandidates(cluster1, cluster1.candidates.concat(newCandidates))
	
	// check logical consistency constraints for the new statements
	map(
	    function(candidate) {
		logicalConsistency(cluster2, candidate)
	    }, result.newStatements
	)

	// and repeat
	return recursivelyExtendCluster( cluster2, thresholdParameters)
    }
}
    


var model = function() {
    // cluster seed:
    // draw from entry points
    var clusterSeed =  uniformDraw(aidaData["entrypoints"])
    // display(["cluster seed", clusterSeed])

    // coreference resolution: we use a mem'ed function
    // to remember which EREs belong to which coref group
    var corefGroupMember = mem(function(corefGroup, ere, confidence) {
	return flip(confidence)
    })

    // from this cluster seed, make a cluster of our internal format
    var cluster0 = clusterObjectInit(clusterSeed, corefGroupMember)

    // compute coref membership throughout
    var cluster1 = corefDo(cluster0)

    // compute additional EREs that are coreferent with the ones in the cluster
    var newEres = corefAdditionalEres(cluster1, cluster1.cluster.ere)
    var cluster2 = clusterObjectUpdateCluster(cluster1, cluster1.cluster.ere.concat(newEres), cluster1.cluster.statements,
					      cluster1.cluster.corefStatements, cluster1.cluster.corefGroups)

    // compute candidates
    var candidates0 = aidaCandidatesFromEre(cluster2, cluster2.cluster.ere.concat(newEres))

    // filter candidates: remove the ones that are equal to ones we already have.
    var candidates1 = candidateRemoveDuplicates(cluster2, candidates0)
    // display(["Initial: removing duplicate candidates. before:", candidates0.length, "after:", candidates1.length])

    // assemble initial cluster
    var clusterInitial = clusterObjectUpdateCandidates(cluster2, candidates1)
						       
    // now do the work
    var clusterFinal = recursivelyExtendCluster(clusterInitial, aidaData.parameters)

    // and report on results
    return {
	statements : sort(clusterFinal.cluster.statements.concat(
	    clusterFinal.cluster.corefStatements)),
	failedQueries : clusterFinal.query.failed
    }
}
			  

var Experiment = function () {
    return Infer( { method : "SMC", particles : 100 }, model)
}

//-------------------------------
var result = Experiment()

display("Writing results to aidaresult.json")
json.write('aidaresult.json', result);

"AIDA baseline done."
