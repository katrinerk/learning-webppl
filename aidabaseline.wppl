// -----------
// usage:
// webppl myscratch.wppl --require webppl-json


// core data structure: cluster.
// looks like this:
// {
// "ere": [
//     "E779987.00064",
//     "V779987.00022"
// ],
// "statements": [
//     202,
//     200,
//     203,
//     206,
//     188
// ],
//    "corefacet_labels" : ["?crash_target", "?crash_event"],
//    "corefacet_fillers" : ["E779987.00064","V779987.00022"],
// "coreconstraints": [
//     [
//      "?crash_event",
//      "Conflict.Attack_Attacker",
//      "?crash_attacker"
//     ],
//     [
//      "?crash_event",
//      "Conflict.Attack_Instrument",
//      "?crash_instrument"
//     ],
//     [
//      "?crash_event",
//      "Conflict.Attack_Place",
//      "?crash_place"
//     ]
//    ],
//    "candidates": [
//     195,
//     201,
//     175,
//     177,
//     179,
//     212,
//     182,
//     184
// ]
// }


//------------------------------------------------
// Data generated by generate_wppl.py
//------------------------------------------------

var jsonData = json.read('aidagraph.json');

//------------------------------------------------
// General functions
//------------------------------------------------

// remove duplicates in an array
var myUnique = function(arr) {
    return reduce(function(index, acc) {
	return arr.indexOf( arr[ index ] ) < index ? acc : [ arr[index ]].concat(acc)
    }, [ ],  _.range(arr.length))
}

// add a second array to a first one while omitting duplicates in the 2nd array
var myAddUnique = function(arr1, arr2) {
    return reduce( function(entry, acc) {
	return arr1.indexOf(entry) > -1 ? acc : [ entry ].concat(acc)
    }, arr1, arr2)
}

// return all members in array1 that are not in array2
var mySetDiff = function(arr1, arr2) {
    return filter(
	function(entry) {
	    return arr2.indexOf(entry) == -1
	}, arr1)
}

// intersection of two arrays
var myIntersection = function(array1, array2) {
    return filter(
	function(e) {
	    return array2.indexOf(e) > -1
	},
	array1)
}
	

// return array minus all elements that are equal to elt
var myArrayMinusElt = function(somearray, elt) {
    return filter(function(e) { return e != elt }, somearray)
}

//-------------------------------
// Proximity measures
//-----

// candidate proximity: how close is the candidate to the cluster?
// cluster: structure as above
// candidate: statement index
var candidateProximity = function(cluster, candidate) {
    return averageProximity(cluster, candidate)
}


// candidate proximity as proximity to a random cluster member
var randomMemberProximity = function(cluster, candidate) {
    var randomMember = uniformDraw(cluster["statements"])
    return jsonData["statementProximity"][randomMember][candidate]
}

// candidate proximity as average proximity:
// 1/clustersize sum_{cluster member i} proximity(i, candidate)
// when proximities are random walk probabilities, this is the probability
// of ending up at candidate when taking a one-step random walk from any cluster member.
var averageProximity = function(cluster, candidate) {
    return sum(map(function(i) { return jsonData["statementProximity"][i][candidate] },
		  cluster["statements"]))  / cluster["statements"].length
}

//-------------------------------
// Helper functions
//-----


// take a list of statement indices and map them to statement labels
var statementIndicesToLabels = function(stmtIxList) {
    return map(
	function(stmtIx) {
	    return jsonData.statements[stmtIx]
	},
	stmtIxList)
}

// take a list of statement indices and map them to a list of statement entries
var statementIndicesToEntries = function(stmtIxList) {
    return map(
	function(stmtIx) {
	    return jsonData.theGraph[ jsonData.statements[stmtIx] ]
	},
	stmtIxList)
}

// find all EREs that are mentioned in a given statement
// statementIndex: index of a statement
var ereInStatement = function(statementIndex) {
    // find the statement going with this index in "statements", then
    // find the entry for the statement in "theGraph"
    var statementEntry = jsonData.theGraph[ jsonData.statements[statementIndex] ]
    
    // return subject and objects for this entry
    // that again have an entry in "theGraph" and have an ERE type
    return myUnique(
	filter(
	    function(entry) {
		return _.has(jsonData.theGraph, entry) &&
		    (jsonData.theGraph[entry].type == "Entity" ||
		     jsonData.theGraph[entry].type == "Event" ||
		     jsonData.theGraph[entry].type == "Relation")
	    },
	    map(
		function(role) {
		    return statementEntry[role] },
		["subject", "object"]
	    )
	)
    )
}


// given a list of ERE names and a list of statements,
// find the statements adjacent to each ERE,
// and form the union of all those with the old statements
var addStatementsFromEre = function(oldStatements, EreList) {
    return reduce(
	function(ere, acc1) {
	    return reduce(
		function(stmt, acc2) {
		    return acc2.indexOf(stmt) > -1 ? acc2 : acc2.concat( stmt )
		},
		acc1, jsonData.theGraph[ere].adjacent)    
	},
	oldStatements, EreList)
}

// given a core constraint of the form [ ?entry1, rel, ?entry2],
// map it into a list of pairs [constraintindex, filler] for known entries.
// so if ?entry1 maps to "abc" in the given core facet label list
// but ?entry2 is not in the core facet label list, the result is
// [[ 0, "abc"], [1, rel]]
var transformCoreConstraint = function(coreConstraint, coreFacetLabels, coreFacetFillers) {
    // indices of entries in core constraint that have entries in coreFacetLabels
    var constraintEntriesInCoreFacet = filter(
	function(i) {
	    coreFacetLabels.indexOf(coreConstraint[i]) > -1
	}, [0, 2]
    )

    // entry for 1 is coreConstraint[1], the relation.
    // entries for all other indices that have entries in coreFacetLabels/coreFacetFillers
    // are their entries in coreFacetStruct
    return [ [1, coreConstraint[1] ] ].concat(
	map(
	    function(i) {
		return [i, coreFacetFillers[ coreFacetLabels.indexOf(coreConstraint[i]) ] ]
	    }, constraintEntriesInCoreFacet
	)
    )
}

// flip side of transformCoreConstraint: show a list of pairs
// only for unknown entries. in the above case [[ 2, "?entry2"]]
var transformCoreConstraintShowUnknown = function(coreConstraint, coreFacetLabels) {
    // indices of entries in core constraint that have entries in coreFacetLabels
    var constraintEntriesNotInCoreFacet = filter(
	function(i) {
	    coreFacetLabels.indexOf(coreConstraint[i]) == -1
	}, [0, 2]
    )

    return map(
	function(i) {
	    return [ i, coreConstraint[i]]
	}, constraintEntriesNotInCoreFacet
    )
}

// get statement triple: given statement index,
// find the statement in theGraph that matches it,
// and transform {subject: A, predicate: B, object:C } to [ A, B, C]
var getStatementTriple = function(stmtIx) {
    var stmt = jsonData.theGraph[ jsonData.statements[stmtIx]]

    return [ stmt.subject, stmt.predicate, stmt.object ]
}

// return all the statement indices from cluster[candidates] that fill the
// given core constraint: for each [index, filler] pair the statement at index has the given filler
var statementIxMatching = function(transformedCoreConstraint, cluster) {    
    return filter(
	function(stmtIndex) {
	    var stmtTriple = getStatementTriple(stmtIndex)
	    
	    return all(
		function(indexFillerConstraint) {
		    return stmtTriple[ indexFillerConstraint[0] ] == indexFillerConstraint[1]
		}, transformedCoreConstraint)
	}, cluster["candidates"])
    
}


//-------------------------------
// Functions that extend a cluster by a given candidate (or don't extend it by the candidate)
//-----

// compute new cluster when the candidate is added
var extendAddCandidate = function(cluster, candidate) {
    var addEre = mySetDiff( ereInStatement(candidate), cluster["ere"])
    var newStatements = cluster["statements"].concat(candidate)
    var newConsidered = cluster["considered"].concat(candidate)
    
    // candidates: old candidates plus statements adjacent to the new EREs,
    // minus statements already considered
    var newCandidates = mySetDiff(
	addStatementsFromEre(
	    cluster["candidates"], addEre),
	newConsidered)

    // display("adding")
    // display(["newEre", addEre])
    // display(["stmt", mySetDiff(newStatements, cluster["statements"])])
    // display(["cand", mySetDiff(newCandidates, cluster["candidates"])])
    // display(["stmt CAP cand", myIntersection(newStatements, newCandidates)])
    
    return {
	ere : cluster["ere"].concat( addEre ),
	statements : newStatements,
	corefacetLabels : cluster["corefacetLabels"],
	corefacetFillers : cluster["corefacetFillers"],
	coreconstraints : cluster["coreconstraints"],
	candidates : newCandidates,
	considered: newConsidered
    }	    
}

// compute new cluster when the candidate is not added
var extendDropCandidate = function(cluster, candidate) {
    var otherCandidates = myArrayMinusElt(cluster["candidates"], candidate)
    var newConsidered = cluster["considered"].concat(candidate)

    // display("not adding")
    // display(["cand", otherCandidates])
    // display(["stmt CAP cand", myIntersection(cluster["statements"], otherCandidates)])
    
	    
    return {
	ere : cluster["ere"],
	statements : cluster["statements"],
	corefacetLabels : cluster["corefacetLabels"],
	corefacetFillers : cluster["corefacetFillers"],
	coreconstraints : cluster["coreconstraints"],
	candidates : otherCandidates,
	considered: newConsidered
    }
}

// core extension: nothing to do. just remove the candidate from the core constraints
var coreExtendNothingToDo = function(cluster, coreConstraint) {
    var newCoreConstraints = myArrayMinusElt(cluster["coreconstraints"], coreConstraint)
    
    return {
	ere : cluster["ere"],
	statements : cluster["statements"],
	corefacetLabels : cluster["corefacetLabels"],
	corefacetFillers : cluster["corefacetFillers"],
	coreconstraints : newCoreConstraints, 
	candidates : cluster["candidates"],
	considered: cluster["considered"]
    }
    
}

// found a candidate to fill a core constraint. add it
var coreExtendAdd = function(cluster, coreConstraint, candidate) {
    // omit the core constraint we just fulfilled
    var newCoreConstraints = myArrayMinusElt(cluster["coreconstraints"], coreConstraint)

    // enter the facets filling the core constraints into the cluster
    var candidateTriple = getStatementTriple(candidate)
    // transformedCoreConstraintShowUnknown has pairs [index, label]
    // where label is a core facet label.
    // there can only be one entry in that list
    var transformedCoreIndexLabel = transformCoreConstraintShowUnknown(coreConstraint, cluster["corefacetLabels"])[0]
    // we are now filling those labels, so keep them in corefacetLabels
    var newCorefacetLabels = cluster["corefacetLabels"].concat(transformedCoreIndexLabel[1])
    // the matching filler is found in candidate, at position index.
    // and actually the transformedCoreConstraint2
    var newCorefacetFillers = cluster["corefacetFillers"].concat( candidateTriple[transformedCoreIndexLabel[0]])

    // display(["filling core facet", transformedCoreIndexLabel[1], candidateTriple[transformedCoreIndexLabel[0]]])
    // display(["facet labels", newCorefacetLabels])
    // display(["fillers", newCorefacetFillers])

    // the rest is as in extendAddCandidate, so use that
    return extendAddCandidate({
	ere : cluster["ere"],
	statements : cluster["statements"],
	corefacetLabels : newCorefacetLabels,
	corefacetFillers : newCorefacetFillers, 
	coreconstraints : newCoreConstraints,
	candidates : cluster["candidates"],
	considered: cluster["considered"]
    }, candidate)
    
}


//-------------------------------
// Model
// Recursive sample for the particle filter
//-----

// choose a random core facet to extend the cluster by.
// cluster: structure, as above
// thresholdParameters: fuzzy threshold for membership.
// (threshold not used by this function, but by extendCluster below
var coreExtendCluster = function(cluster, thresholdParameters) {
    if( cluster.coreconstraints.length == 0) {
	// done with core constraints. now add arbitrary other elements
	// display(["no more core constraints", cluster])
	return extendCluster(cluster, thresholdParameters)
    } else {
	// core constraints remaining. randomly choose one of them.
	var coreConstraint = uniformDraw(cluster["coreconstraints"])
	// display(["coreConstraint", coreConstraint])

	// coreConstraint has the form ?entry1 Rel ?entry2
	// transform into a list of pairs [index, filler]
	// for all indices in coreConstraint for which the filler is either Rel,
	// or given in corefacets.
	// If transformedCoreConstraint has a length of 3, then all constraint pieces
	// already have entries in corefacets -- the constraint is already fulfilled.
	// Length 1 means neither ?entry1 nor ?entry2 is in corefacets, and we cannot
	// fulfill the constraint from the current candidates.
	// Length 2: We need to find a candidate to fill this constraint.
	var transformedCoreConstraint = transformCoreConstraint(coreConstraint,
								cluster["corefacetLabels"], cluster["corefacetFillers"])
	// display(["transformedCoreConstraint", transformedCoreConstraint])

	if (transformedCoreConstraint.length == 3 ) {
	    // nothing to do, this core constraint is already fulfilled
	    // display("coreConstraint done")
	    return coreExtendCluster(coreExtendNothingToDo(cluster, coreConstraint), thresholdParameters)
	} else {
	    if (transformedCoreConstraint.length == 1) {
		// abandon this sample: we cannot possibly fill this constraint at this point
		// display("coreConstraint not doable")
		condition(false)
	    } else {
		// draw a random statement that can fill this core facet.
		// we require that there is at least one statement that can fill the core facet,
		// otherwise we abandon this cluster. 
		var candidates = statementIxMatching(transformedCoreConstraint, cluster)
		// display(["coreConstraint candidates", candidates])
		if (candidates.length == 0) {
		    condition(false)
		} else {
		    var candidate = uniformDraw(candidates)
		    // display(["chosen candidate", candidate])
		    return coreExtendCluster(coreExtendAdd(cluster, coreConstraint, candidate), thresholdParameters)
		}
	    }
	}
    }
}

// choose a random statement to extend the cluster by.
// flip a coin to see if it should be added to the cluster, or dropped.
//
// cluster: structure
// thresholdParameters: threshold for membership
var extendCluster = function(cluster, thresholdParameters) {

    if (cluster["candidates"].length == 0) {
	// we have considered all candidates, the cluster is finished.
	return cluster;
    } else {
	// consider a candidate
	var candidate = uniformDraw(cluster["candidates"])
	    
	// choose a threshold for it
	var tau = gamma( thresholdParameters )

	// choose whether it is a member
	var isMember = flip()

	// display(["candidate", candidate, jsonData["statements"][candidate]])
	// display(["isMember", isMember, "tau", tau, "proximity", candidateProximity(cluster, candidate)])
    

    	// The candidate needs to be on the right side of threshold tau
    	if (isMember) {
    	    condition( candidateProximity(cluster, candidate) > tau)

    	    return extendCluster(extendAddCandidate(cluster, candidate), thresholdParameters)
	    
    	} else {
    	    condition( candidateProximity( cluster, candidate) < tau)
	    
    	    return extendCluster(extendDropCandidate(cluster, candidate), thresholdParameters)
    	}
    }
}

		  

//-------------------------------
// Inference
//-----



var model = function(clusterSeed) {
    var shapeTau = 5.0
    var scaleTau = 0.01
    // display("parameters")
    // display([shapeTau, scaleTau])

    var cluster = coreExtendCluster(clusterSeed, {shape: shapeTau, scale: scaleTau})
    return sort(
	statementIndicesToLabels(
	    cluster["statements"]
	).concat(
	    cluster["ere"]
	))
}
			  

var Experiment = function () {
    // cluster seed:
    // draw from entry points,
    // then add the list of considered statements: added plus non-added. currently,
    // this is simply the list of statements in the seed.
    var clusterSeedIncomplete =  uniformDraw(jsonData["entrypoints"])
    var clusterSeed = _.extend(clusterSeedIncomplete, { considered : clusterSeedIncomplete["statements"]} )
    
    // display("starting point")
    // display(clusterSeed)


    var result = Infer( { method : "SMC", particles : 1000 }, function() {
	return model(clusterSeed)
    })

    return result
}

//-------------------------------
var result = Experiment()

json.write('aidaresult.json', result);

"AIDA baseline done"
