// -----------
// usage:
// webppl aidabaseline.wppl --require webppl-json


// core data structure: cluster.


//------------------------------------------------
// Data generated by generate_wppl.py
//------------------------------------------------

// entries:
// theGraph: characterization of statement and ERE nodes in the graph.
//           mapping from node labels to node structures
// statementProximity: pairwise proximity between statement nodes
//           sparse, hence encoded as a mapping from statement node labels
//           to statement node labels to proximities
// entryPoints: list of entryPoint structures;
//           they are alternative cluster seeds to start from
//           an entry point is a structure that describes a cluster,
//           the core data structure described above
var aidaData = json.read('aidagraph.json');

//------------------------------------------------
// Access to the data generated by generate_wppl.py
//------------------------------------------------

// given a graph label, find the matching entry
var aidaEntry = function(label) {
    return aidaData.theGraph[ label ]
}

// read the proximity between two statements off the AIDA graph
var aidaProximity = function(stmt1, stmt2) {
    if (_.has(aidaData.statementProximity, stmt1) && _.has(aidaData.statementProximity[stmt1], stmt2)) {
	// we have an entry for stmt1, and a proximity to stmt2: return that
	return aidaData.statementProximity[stmt1][stmt2]
    } else {
	return 0.0
    }
}


// take a list of statements and map them to a list of statement entries
var aidaStatementEntries = function(stmtList) {
    return map(
	function(stmt) {
	    return aidaEntry(stmt)
	},
	stmtList)
}


// find all EREs that are mentioned in a given statement
var aidaEreInStatement = function(statement) {
    // retrieve the entry 
    var statementEntry = aidaEntry(statement)
    
    // return subject and objects for this entry
    // that again have an entry in "theGraph" and have an ERE type
    return myUnique(
	filter(
	    function(entry) {
		return _.has(aidaData.theGraph, entry) &&
		    (aidaData.theGraph[entry].type == "Entity" ||
		     aidaData.theGraph[entry].type == "Event" ||
		     aidaData.theGraph[entry].type == "Relation")
	    },
	    map(
		function(role) {
		    return statementEntry[role] },
		["subject", "object"]
	    )
	)
    )
}


// given a list of ERE names and a list of statements,
// find the statements adjacent to each ERE,
// and form the union of all those with the old statements
var aidaAddStatementsFromEre = function(oldStatements, EreList) {
    return reduce(
	function(ere, acc1) {
	    return reduce(
		function(stmt, acc2) {
		    return acc2.indexOf(stmt) > -1 ? acc2 : acc2.concat( stmt )
		},
		acc1, aidaData.theGraph[ere].adjacent)    
	},
	oldStatements, EreList)
}

// get statement triple: given statement index,
// find the statement in theGraph that matches it,
// and transform {subject: A, predicate: B, object:C } to [ A, B, C]
var aidaStatementTriple = function(stmt) {
    var stmtEntry = aidaEntry(stmt)

    return [ stmtEntry.subject, stmtEntry.predicate, stmtEntry.object ]
}

// return all the statements  from cluster.candidates that fill the
// given core constraint: for each [stmt, filler] pair the statement  has the given filler
var aidaStatementMatching = function(transformedCoreConstraint, cluster) {    
    return filter(
	function(stmt) {
	    var stmtTriple = aidaStatementTriple(stmt)
	    
	    return all(
		function(indexFillerConstraint) {
		    return stmtTriple[ indexFillerConstraint[0] ] == indexFillerConstraint[1]
		}, transformedCoreConstraint)
	}, cluster.candidates)
    
}



//------------------------------------------------
// Core facet handling
//------------------------------------------------

// given a core constraint of the form [ ?entry1, rel, ?entry2],
// map it to a structure that indicates that has been filled in the cluster
// and what is still open.
// filled entries: 
// if ?entry1 maps to "abc" in the given core facet label list
// and "abc" and "def" are in the same cluster,
// but ?entry2 is not in the core facet label list, the result is
// [[ 0, ["abc", "def"]], [1, [rel]]]
// open entries: pair of [ index, corefacetlabel]
// in our example [2, ?entry2]
var coreMakeStruct = function(coreConstraint, cluster) {
    // indices of entries in core constraint that have entries in coreFacetLabels
    var entryList = map(
	function(i) {
	    var entryIndex = cluster.core.facetLabels.indexOf(coreConstraint[i])
	    return entryIndex > -1 ?
		{ filled : true,
		  filler : [ cluster.core.facetFillers[ entryIndex] ],
		  label  : coreConstraint[i]
		}
	    :
	        { filled : false,
		  filler : [ ],
		  label : coreConstraint[i]
		}
	}, [0, 2])


    return {
	predicate : coreConstraint[1],
	filled : 
	    map(
		function(i) {
		    return [i, cluster.core.facetFillers[ cluster.core.coreFacetLabels.indexOf(coreConstraint[i]) ] ]
	    }, constraintEntriesInCoreFacet
	)
    }
		    
}

var aidaTransformCoreC = function(coreConstraint, coreFacetLabels, coreFacetFillers) {
    return true
}

// flip side of transformCoreConstraint: show a list of pairs
// only for unknown entries. in the above case [[ 2, "?entry2"]]
var aidaTransformCoreCFlip = function(coreConstraint, coreFacetLabels) {
    // indices of entries in core constraint that have entries in coreFacetLabels
    var constraintEntriesNotInCoreFacet = filter(

    return map(
	function(i) {
	    return [ i, coreConstraint[i]]
	}, constraintEntriesNotInCoreFacet
    ))
}




//------------------------------------------------
// General functions
//------------------------------------------------

// remove duplicates in an array
var myUnique = function(arr) {
    return reduce(function(index, acc) {
	return arr.indexOf( arr[ index ] ) < index ? acc : [ arr[index ]].concat(acc)
    }, [ ],  _.range(arr.length))
}

// add a second array to a first one while omitting duplicates in the 2nd array
var myAddUnique = function(arr1, arr2) {
    return reduce( function(entry, acc) {
	return arr1.indexOf(entry) > -1 ? acc : [ entry ].concat(acc)
    }, arr1, arr2)
}

// return all members in array1 that are not in array2
var mySetDiff = function(arr1, arr2) {
    return filter(
	function(entry) {
	    return arr2.indexOf(entry) == -1
	}, arr1)
}

// intersection of two arrays
var myIntersection = function(array1, array2) {
    return filter(
	function(e) {
	    return array2.indexOf(e) > -1
	},
	array1)
}
	

// return array minus all elements that are equal to elt
var myArrayMinusElt = function(somearray, elt) {
    return filter(function(e) { return e != elt }, somearray)
}

//-------------------------------
// Proximity measures
//-----

// candidate proximity: how close is the candidate to the cluster?
// cluster: structure as above
// candidate: statement label
var candidateProximity = function(cluster, candidate) {
    return averageProximity(cluster, candidate)
}


// candidate proximity as proximity to a random cluster member
var randomMemberProximity = function(cluster, candidate) {
    var randomMember = uniformDraw(cluster.statements)
    return aidaProximity(randomMember, candidate)
}

// candidate proximity as average proximity:
// 1/clustersize sum_{cluster member i} proximity(i, candidate)
// when proximities are random walk probabilities, this is the probability
// of ending up at candidate when taking a one-step random walk from any cluster member.
var averageProximity = function(cluster, candidate) {
    return sum(
	map(
	    function(stmt) {
		return aidaProximity(stmt, candidate)
	    }, cluster.statements))  / cluster.statements.length
}



//-------------------------------
// Logical consistency
//-----

var subjectUniquePredicates = ["hasKBEntry", "type"];
var objectUniquePredicates = [ 'Life.Die_Agent', 'Movement.TransportPerson_Person',
			       'Manufacture.Artifact_Manufacturer', 'Movement.TransportPerson_Origin',
			       'Life.Die_Victim', 'Manufacture.Artifact_Artifact', 'Conflict.Attack_Attacker',
			       'Justice.Convict_Defendant', 'Transaction.TransferOwnership_Thing', 'GeneralAffiliation.APORA_Affiliation',
			       'Life.Die_Instrument', 'Conflict.Attack_Instrument', 'Justice.Appeal_Prosecutor',
			       'Movement.TransportArtifact_Destination', 'Contact.Broadcast_Broadcaster',
			       'Conflict.Attack_Target', 'GeneralAffiliation.Sponsorship_Sponsor', 'Movement.TransportArtifact_Origin',
			       'Justice.Appeal_Defendant', 'Justice.Convict_Adjudicator', 'Movement.TransportArtifact_Artifact',
			       'Transaction.TransferOwnership_Recipient', 'Movement.TransportArtifact_Agent',
			       'OrganizationAffiliation.EmploymentMembership_Organization', 'Transaction.TransferOwnership_Giver',
			       'Transaction.TransferOwnership_Beneficiary', 'GeneralAffiliation.Sponsorship_Entity',
			       'Movement.TransportArtifact_Instrument', 'Movement.TransportPerson_Agent', 'Movement.TransportPerson_Instrument',
			       'GeneralAffiliation.MORE_Affiliation' ];

// subject uniqueness:
// if p is a subject unique predicate, then
// if e1 p e2 and e1 p e3 then e2 = e3
// This is a hard constraint
var constSubjectUnique = function(clusterTriples, candidateTriple) {
    // test for subject uniqueness only if our candidate has a predicate that is subject-unique
    if (subjectUniquePredicates.indexOf(candidateTriple[1]) > -1) {
	map(
	    function(clusterTriple) {
		condition(candidateTriple[0] != clusterTriple[0] || candidateTriple[1] != clusterTriple[1] || candidateTriple[2] == clusterTriple[2])
	    }, clusterTriples)
    }
}

// object uniqueness:
// if p is an object unique predicate, then
// if e1 p e2 and e3 p e2 then e1 = e3
// This is a soft constraint
var constObjectUnique = function(clusterTriples, candidateTriple) {
    // test for subject uniqueness only if our candidate has a predicate that is subject-unique
    if (objectUniquePredicates.indexOf(candidateTriple[1]) > -1) {
	map(
	    function(clusterTriple) {
		factor(candidateTriple[2] != clusterTriple[2] || candidateTriple[1] != clusterTriple[1] || candidateTriple[0] == clusterTriple[0] ?
		       0 : -3)
	    }, clusterTriples)
    }
}

// do use type statements
var constUseTypes = function(cluster, candidateEntry) {
    factor(candidateEntry.predicate == "type" ? 0.1 : 0)
}

// take confidence into account
var constConfidence = function(cluster, candidateEntry) {
    factor(Math.log(candidateEntry.conf))
}

// a list of all the constraints to apply to pairs of statement triples.
var pairwiseConstraints = [ constSubjectUnique, constObjectUnique ];
// a list of all constraints to apply to the candidate statement
var unaryConstraints = [ constUseTypes, constConfidence ];

// test the logical consistency of the given cluster if candidate was to be added to it
// cluster: structure.
// candidate: statement index
var logicalConsistency = function(cluster, candidate) {
    // map statements to triples
    var candidateTriple = aidaStatementTriple(candidate)
    var clusterTriples = map(
	function(i) {
	    return aidaStatementTriple(i)
	}, cluster.statements)

    // apply binary constraints on triples
    map(
	function(constraintFn) {
	    constraintFn(clusterTriples, candidateTriple)
	}, pairwiseConstraints)

    // and apply unary constraints on the candidat entry
    var candidateEntry = aidaEntry(candidate)
    map(
	function(constraintFn) {
	    constraintFn(cluster, candidateEntry)
	}, unaryConstraints)
}


//-------------------------------
// Functions that check and manipulate cluster objects
//-----

var clusterNoMoreCoreConstraints = function(cluster) {
    return cluster.core.constraints.length == 0
}

var clusterNoMoreCandidateStatements = function(cluster) {
    return cluster.candidates.length == 0
}

// compute new cluster when the candidate is added
var clusterAddCandidate = function(cluster, candidate) {
    
    // compute updated cluster components
    var newEre = mySetDiff( aidaEreInStatement(candidate), cluster.ere)
    var updatedStatements = cluster.statements.concat(candidate)
    var updatedConsidered = cluster.considered.concat(candidate)
    
    // candidates: old candidates plus statements adjacent to the new EREs,
    // minus statements already considered
    var updatedCandidates = mySetDiff(
	aidaAddStatementsFromEre(cluster.candidates, newEre),
	updatedConsidered)

    // display("adding")
    // display(["newEre", addEre])
    // display(["stmt", mySetDiff(newStatements, cluster.statements)])
    // display(["cand", mySetDiff(newCandidates, cluster.candidates)])
    // display(["stmt CAP cand", myIntersection(newStatements, newCandidates)])
    
    return {
	newCluster : {
	    ere : cluster.ere.concat( newEre ),
	    statements : updatedStatements,
	    core : cluster.core,
	    candidates : updatedCandidates,
	    considered: updatedConsidered
	},
	newERE : newEre,
	newStatements : [ candidate ]
    }
}

// compute new cluster when the candidate is not added
var clusterDropCandidate = function(cluster, candidate) {
    var updatedCandidates = myArrayMinusElt(cluster.candidates, candidate)
    var updatedConsidered = cluster.considered.concat(candidate)

    // display("not adding")
    // display(["cand", updatedCandidates])
    // display(["stmt CAP cand", myIntersection(cluster.statements, updatedCandidates)])
    
	    
    return {
	newCluster : {
	    ere : cluster.ere,
	    statements : cluster.statements,
	    core : cluster.core,
	    candidates : updatedCandidates,
	    considered: updatedConsidered
	},
	newERE : [ ],
	newStatements = [ ]
    }
}

// core extension: nothing to do. just remove the candidate from the core constraints
var clusterCoreNothingToDo = function(cluster, coreConstraint) {
    var updatedCoreConstraints = myArrayMinusElt(cluster.core.constraints, coreConstraint)
    
    return {
	newCluster : { 
	    ere : cluster.ere,
	    statements : cluster.statements,
	    core : {
		facetLabels : cluster.core.facetLabels,
		facetFillers : cluster.core.facetFillers,
		constraints : updatedCoreConstraints
	    },
	    candidates : cluster.candidates,
	    considered : cluster.considered
	},
	newERE : [ ],
	newStatements : [ ]
    }
}



// found a candidate to fill a core constraint. add it
var clusterCoreAdd = function(cluster, coreConstraint, candidate) {
    
    // omit the core constraint we just fulfilled
    var updatedCoreConstraints = myArrayMinusElt(cluster.core.constraints, coreConstraint)
    // enter the facets filling the core constraints into the cluster
    var candidateTriple = aidaStatementTriple(candidate)
    // transformedCoreConstraintShowUnknown has pairs [index, label]
    // where label is a core facet label.
    // there can only be one entry in that list
    var transformedCoreIndexLabel = aidaTransformCoreCFlip(coreConstraint, cluster.core.facetLabels)[0]
    // we are now filling those labels, so keep them in corefacetLabels
    var updatedCorefacetLabels = cluster.core.facetLabels.concat(transformedCoreIndexLabel[1])
    // the matching filler is found in candidate, at position index.
    // and actually the transformedCoreConstraint2
    var updatedCorefacetFillers = cluster.core.facetFillers.concat( candidateTriple[transformedCoreIndexLabel[0]])

    // display(["filling core facet", transformedCoreIndexLabel[1], candidateTriple[transformedCoreIndexLabel[0]]])
    // display(["facet labels", newCorefacetLabels])
    // display(["fillers", newCorefacetFillers])

    // the rest is as in clusterAddCandidate, so use that
   return clusterAddCandidate({
       ere : cluster.ere,
       statements : cluster.statements,
       core: {
	   facetLabels : updatedCorefacetLabels,
	   facetFillers : updatedCorefacetFillers,
	   constraints : updatedCoreConstraints,
       },
       candidates : cluster.candidates,
       considered: cluster.considered
   }, candidate)   
}


//-------------------------------
// Extending the cluster
//-----

// extend the cluster once, either by choosing a core constraint to fill, if there is one,
// or by choosing a statement that we haven't considered yet that is adjacent to one
// of the cluster's EREs
var extendClusterOnce = function(cluster, thresholdParameters) {
    // if there are no core constraints, add a candidate statement from the frontier.
    if (clusterNoMoreCoreConstraints(cluster)) {
	return extendClusterOnceByCandidateStatement(cluster, thresholdParameters)
    } else {
	// we do still have core constraints to do
	return extendClusterOnceByCoreConstraint(cluster, thresholdParameters)
    }
}

// extend the cluster once by choosing a core constraint to fill
// this returns a structure with entries
// newCluster: updated cluster
// newERE: EREs added to the frontier of the cluster
// newStatements: statements added to the cluster
var extendClusterOnceByCoreConstraint = fuction(cluster, thresholdParameters) {
    if (clusterNoMoreCoreConstraints(cluster)) {
	// nothing to do after all
	return {
	    newCluster : cluster,
	    newERE : [ ],
	    newStatements : [ ]
	}
    } else {
	// core constraints remaining. randomly choose one of them.
	var coreConstraint = uniformDraw(cluster.core.constraints)
	// display(["coreConstraint", coreConstraint])

	// coreConstraint has the form ?entry1 Rel ?entry2
	// transform into a list of pairs [index, filler]
	// for all indices in coreConstraint for which the filler is either Rel,
	// or given in corefacets.
	// If transformedCoreConstraint has a length of 3, then all constraint pieces
	// already have entries in corefacets -- the constraint is already fulfilled.
	// Length 1 means neither ?entry1 nor ?entry2 is in corefacets, and we cannot
	// fulfill the constraint from the current candidates.
	// Length 2: We need to find a candidate to fill this constraint.
	var transformedCoreConstraint = aidaTransformCoreC(coreConstraint,
							   cluster.core.facetLabels, cluster.core.facetFillers)

	if (transformedCoreConstraint.length == 3 ) {
	    // nothing to do, this core constraint is already fulfilled
	    // display("coreConstraint done")
	    return clusterCoreNothingToDo(cluster, coreConstraint)
	} else {
	    if (transformedCoreConstraint.length == 1) {
		// abandon this sample: we cannot possibly fill this constraint at this point
		display(["coreConstraint cannot be filled", coreConstraint])
		// condition(false)
		condition(-5)
		return clusterCoreNothingToDo(cluster, coreConstraint)
	    } else {
		// draw a random statement that can fill this core facet.
		// we require that there is at least one statement that can fill the core facet,
		// otherwise we abandon this cluster. 
		var candidates = aidaStatementMatching(transformedCoreConstraint, cluster)
		// display(["coreConstraint candidates", candidates])
		if (candidates.length == 0) {
		    display(["coreConstraint cannot be filled", coreConstraint])
		    // condition(false)
		    condition(-5)
		    return clusterCoreNothingToDo(cluster, coreConstraint)
		} else {
		    var candidate = uniformDraw(candidates)
		    // display(["chosen candidate", candidate])
		    return clusterCoreAdd(cluster, coreConstraint, candidate)
		}
	    }
	}
    }
}

// extend the cluster once by choosing a statement from the candidate list
// this returns a structure with entries
// newCluster: updated cluster
// newERE: EREs added to the frontier of the cluster
// newStatements: statements added to the cluster
var extendClusterOnceByCandidateStatement = function(cluster, thresholdParameters) {
    if (clusterNoMoreCandidateStatements(cluster)) {
	// nothing to do after all
	return {
	    newCluster : cluster,
	    newERE : [ ],
	    newStatements : [ ]
	}
    } else {
	// consider a candidate
	var candidate = uniformDraw(cluster.candidates)
	    
	// choose a threshold for it
	var tau = gamma( thresholdParameters )

	// choose whether it is a member
	var isMember = flip()

	// display(["candidate", candidate, aidaData["statements"][candidate]])
	// display(["isMember", isMember, "tau", tau, "proximity", candidateProximity(cluster, candidate)])
    

    	// The candidate needs to be on the right side of threshold tau
    	if (isMember) {
    	    condition( candidateProximity(cluster, candidate) > tau)

    	    return clusterAddCandidate(cluster, candidate)
	    
    	} else {
    	    condition( candidateProximity( cluster, candidate) < tau)
	    
    	    return clusterDropCandidate(cluster, candidate)
    	}
    }
}


//-------------------------------
// Model
// Recursive sample for the particle filter
//-----

var recursivelyExtendCluster = function(cluster, thresholdParameters) {

    if (clusterNoMoreCoreConstraints(cluster) && clusterNoMoreCandidateStatements) {
	// nothing more to add to this cluster, end recursion
	return cluster;
    } else {
    
	// try to do one step of additions to the cluster
	// this returns a structure with entries
	// newCluster: updated cluster
	// newERE: EREs added to the frontier of the cluster
	// newStatements: statements added to the cluster
	var result = extendClusterOnce(cluster, thresholdParameters)
	
	// take coreference statements into account
	
	// check logical consistency constraints for the new statements
	map(
	    function(candidate) {
		logicalConsistency(result.newCluster, candidate)
	    }, result.newStatements
	)
	
	// and repeat
	return recursivelyExtendCluster( result.newCluster, thresholdParameters)
    }
}
    

//-------------------------------
// Inference
//-----



var model = function(clusterSeed) {
    var shapeTau = 5.0
    var scaleTau = 0.01
    // display("parameters")
    // display([shapeTau, scaleTau])

    var cluster = recursivelyExtendCluster(clusterSeed, {shape: shapeTau, scale: scaleTau})
    return sort(cluster.statements.concat(cluster.ere))
}
			  

var Experiment = function () {
    // cluster seed:
    // draw from entry points,
    // then add the list of considered statements: added plus non-added. currently,
    // this is simply the list of statements in the seed.
    var clusterSeedIncomplete =  uniformDraw(aidaData["entrypoints"])
    var clusterSeed = _.extend(clusterSeedIncomplete, { considered : clusterSeedIncomplete["statements"]} )
    
    // display("starting point")
    // display(clusterSeed)


    var result = Infer( { method : "SMC", particles : 1000 }, function() {
	return model(clusterSeed)
    })

    return result
}

//-------------------------------
var result = Experiment()

json.write('aidaresult.json', result);

"AIDA baseline done"
