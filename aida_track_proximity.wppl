// -----------
// usage:
// webppl aidabaseline.wppl --require webppl-json


// core data structure: cluster.

// possible improvements:
// * keep an array of prototypical included statements (without coref duplicates),
//   run logical consistency checks only against that, and report only these statements in the end
//   to make the output smaller
// * in aidaData.theGraph, let each statement have a list of possible coref duplicates
//   as checking for duplicates is mainly what makes this so slow
// * coref statements: only report the ones that are adjacent to the custer
// * cluster membership: move to factor rather than condition for stuff on the wrong side of tau

//------------------------------------------------
// Data generated by generate_wppl.py
//------------------------------------------------

// entries:
// theGraph: characterization of statement and ERE nodes in the graph.
//           mapping from node labels to node structures
// statementProximity: pairwise proximity between statement nodes
//           sparse, hence encoded as a mapping from statement node labels
//           to statement node labels to proximities
// entryPoints: list of entryPoint structures;
//           they are alternative cluster seeds to start from
//           an entry point is a structure that describes a cluster,
//           the core data structure described above
display("Reading aidagraph.json from " + argv.aidagraph)
var aidaData = json.read(argv.aidagraph);
display("Reading aidaquery.json from " + argv.aidaquery)
var aidaQuery = json.read(argv.aidaquery);
// display("done reading aidagraph.json")

//------------------------------------------------
// General functions
//------------------------------------------------

// remove duplicates in an array
var myArrUnique = function(arr) {
    return reduce(function(index, acc) {
	return arr.indexOf( arr[ index ] ) < index ? acc : [ arr[index ]].concat(acc)
    }, [ ],  _.range(arr.length))
}


// return all members in array1 that are not in array2
var myArrDiff = function(arr1, arr2) {
    return filter(
	function(entry) {
	    return arr2.indexOf(entry) == -1
	}, arr1)
}

	

// return array minus all elements that are equal to elt
var myArrayMinusElt = function(somearray, elt) {
    return filter(function(e) { return e != elt }, somearray)
}

var mySetEmpty = function(n) {
    return mapN(function(i) { return 0 }, n)
}

var mySetLength = function(set) {
    return sum(set)
}

var mySetAdd = function(set, k) {
    return mapN(function(i) { return i == k ? 1 : set[i] }, set.length)
}

// set difference: make sure we return it as 1's and 0's rather than true/false
var mySetDiff = function(set1, set2) {
    return mapN(function(i) { return 0 + (set1[i] && !set2[i]) }, set1.length)
}

var mySetUnion = function(set1, set2) {
    return mapN(function(i) { return 0 + (set1[i] || set2[i]) }, set1.length)
}

var mySetUpdate = function(set, arr) {
    return reduce(
	function(ix, accSet) {
	    return mySetAdd(accSet, ix)
	}, set, arr)
}

// return the indices that are set to true
var mySetDecode = function(set) {
    return filter( function(i) { return set[i] }, _.range(set.length))
}

// draw a random index from the set
var mySetDraw = function(set) {
    return categorical({ps: set, vs: _.range(set.length)})
}

//------------------------------------------------
// Coreference handling via unification
//------------------------------------------------


// seqConstraintVar is a sequence of core constraint variables from all entrypoints, without duplicates.
// we need this to determine indices for constraint variables to use in unifiers.
var seqConstraintVar = filter(
    function(entry) {
	// retain only variables, i.e. stuff that doesn't have an (ERE) entry in the graph
	return !(_.has(aidaData.theGraph, entry))
    }, myArrUnique(
	// remove duplicates in
	// flattened arguments of query constraints
	reduce(
	    function(entryPoint, acc1) {
		return reduce(
		    function(cconstraint, acc2) {
			return [ cconstraint[0], cconstraint[2]].concat(acc2)
		    }, acc1, entryPoint.queryConstraints)
	    }, [ ], aidaQuery.entrypoints)
    )
)

// make an initial unifier that maps each ERE or variable to itself.
var unifierInitial = function() {
    return _.range(aidaData.ere.length + seqConstraintVar.length)
}


// does this term have a unifier
var unifierExists = function(item) {
    return _.has(aidaData.theGraph, item) || seqConstraintVar.indexOf(item) > -1
}
// returns the index of an ERE or constraint variable
var unifierIndex = function(ere) {
    return !unifierExists(ere)
	? -1
	:
	_.has(aidaData.theGraph, ere)
	? aidaData.theGraph[ere].index
	: (aidaData.ere.length + seqConstraintVar.indexOf(ere))
}

// returns the unifier of an ERE or constraint variable
var unifierGet = function(ere, unifInfo) {
    if (!unifierExists(ere)) {
	return -1
    } else {
	return unifInfo[ unifierIndex(ere) ]
    }
}

// returns all EREs that have a particular unifier
var unifierGetOriginals = function(ereUnif, unifInfo) {
    return map(
	// map indices to entity/event labels
	function(i) {
	    return aidaData.ere[i]
	},
	// indices of unifInfo that have ereUnif as unifier
	filter(
	    function(i) {
		return unifInfo[i] == ereUnif
	    }, _.range(unifInfo.length)
	)
    )
}

// true if two EREs or constraint variables have the same unifier
var unifierEquals = function(ere1, ere2, unifInfo) {
    return unifierExists(ere1) &&
	unifierExists(ere2) &&
	unifierGet(ere1, unifInfo) == unifierGet(ere2, unifInfo)
}

// unbound core variable:
// true if coreVar doesn't have an entry in theGraph (so it is a core variable)
// and its unifier is itself
var unifierVarUnbound = function(coreVar, unifInfo) {
    return unifierExists(coreVar) &&
	!(_.has(aidaData.theGraph, coreVar)) &&
	unifierGet(coreVar, unifInfo) == unifierIndex(coreVar)
}

// unifiable: either they are already in the same equivalence class,
// or one of them is an unbound core variable.
var unifierUnifiable = function(ere1, ere2, unifInfo) {
    return unifierVarUnbound(ere1, unifInfo) ||
	unifierVarUnbound(ere2, unifInfo) ||
	unifierEquals(ere1, ere2, unifInfo)
}

// given two unifiers, decide which becomes the unifier of both and which becomes obsolete.
// returns structure with entries newUnifier, obsoleteUnifier.
var unifierDecideUnifier = function(unifier1, unifier2) {
    return unifier1 < unifier2 ?
	{
	    newUnifier : unifier1,
	    obsoleteUnifier : unifier2
	}
    :
        {
	    newUnifier : unifier2,
	    obsoleteUnifier : unifier1
	}
}
	    

// returns a new unifInfo in which ere1 and ere2 have been unified
var unifierUnify = function(ere1, ere2, unifInfo) {
    if (!unifierExists(ere1) || !unifierExists(ere2)) {
	return unifInfo
    } else {
	var unifier1 = unifierGet(ere1, unifInfo)
	var unifier2 = unifierGet(ere2, unifInfo)

	if (unifier1 == unifier2) {
	    return unifInfo
	} else {
	    var unifierOrder = unifierDecideUnifier(unifier1, unifier2)
	    return map(
		function(unifier) {
		    return unifier == unifierOrder.obsoleteUnifier ? unifierOrder.newUnifier : unifier
		}, unifInfo)
	}
    }
}

// given two statement arguments, say they are the same
// if they have unifiers and they are the same,
// of if they are constants that are the same
var unifierArgEqual = function(arg1, arg2, unifInfo) {
    if (unifierExists(arg1) && unifierExists(arg2)) {
	// two EREs or variables
	return unifierEquals(arg1, arg2, unifInfo)
    } else {
	if (!unifierExists(arg1) && !unifierExists(arg2)) {
	    // two non-EREs, non-variables
	    return arg1 == arg2
	} else {
	    // one ERE, one constant or something like that
	    return false
	}
    }
}


// Given two statement labels, determine whether they are the same statement
// modulo coref
var unifierStmtEqual = function(l1, l2, unifInfo) {
    var sEntry1 = aidaEntry(l1)
    var sEntry2 = aidaEntry(l2)
    
    return sEntry1.predicate == sEntry2.predicate &&
	unifierArgEqual(sEntry1.subject, sEntry2.subject, unifInfo) &&
	unifierArgEqual(sEntry1.object, sEntry2.object, unifInfo)
}

//------------------------------------------------
// Access to the data generated by generate_wppl.py
//------------------------------------------------

// given a graph label, find the matching entry
var aidaEntry = function(label) {
    return aidaData.theGraph[ label ]
}

var aidaIndex = function(label) {
    return aidaEntry(label).index
}

var aidaIsEre = function(label) {
    return _.has(aidaData.theGraph, label) &&
	(aidaData.theGraph[label].type == "Entity" ||
	 aidaData.theGraph[label].type == "Event" ||
	 aidaData.theGraph[label].type == "Relation")
}

//
var aidaStmtSetUpdate = function(set, arr) {
    return mySetUpdate(set, map(function(stmt) { return aidaIndex(stmt) }, arr))
}

// given a mySet of statements, map it to the statement labels
var aidaDecodeStmtSet = function(set) {
    return map(function(i) { return aidaData.statements[i] }, mySetDecode(set))
}

var aidaDecodeEreArray = function(ereIndices) {
    return map(function(i) { return aidaData.ere[i] }, ereIndices)
}

// given a list of EREs, map it to their unifiers (ee indices), and remove duplicates
var aidaCanonicalEres = function(eres, unifInfo) {
    return myArrUnique(
	map(
	    function(ere) {
		return unifierGet(ere, unifInfo)
	    }, eres
	)
    )
}

// given an array of statements, determine unification aliases, 
// and return as a mySet.
// don't include items listed in excludeme
// add the new statements and all their duplicates to the set
var aidaStatementAliases = function(statements, excludeme, unifInfo) {
    var extendedStatements = filter(
	function(stmt) {
	    return (!excludeme[ aidaIndex(stmt) ] &&
		    any(
			function(stmt2) {
			    return unifierStmtEqual(stmt, stmt2, unifInfo)
			}, statements))
		   }, aidaData.statements)

    return aidaStmtSetUpdate(mySetEmpty(aidaData.statements.length), extendedStatements)
}

// find all statements adjacent to the given EREs and aliases of the EREs,
// and return as a mySet.
var aidaCandidates = function(ereIndices, unifInfo) {
    // for all given EREs: use unifierGetOriginals to determine aliases,
    // then adjacent statements in theGraph
    var candidates = reduce(
	function(ereIndex, acc1) {
	    return reduce(
		function(ere, acc2) {
		    return _.has(aidaData.theGraph, ere) ? aidaData.theGraph[ere].adjacent.concat(acc2) : acc2
		}, acc1, unifierGetOriginals(ereIndex, unifInfo))
	}, [ ], ereIndices)

    return aidaStmtSetUpdate(mySetEmpty(aidaData.statements.length), candidates)
}

// find all EREs that are mentioned in a given statement
var aidaEreInStatement = function(statement) {
    // retrieve the entry 
    var statementEntry = aidaEntry(statement)
    
    // return subject and objects for this entry
    // that again have an entry in "theGraph" and have an ERE type
    return myArrUnique(
	filter(aidaIsEre, map(
		function(role) {
		    return statementEntry[role] },
		["subject", "object"]
	    )
	)
    )
}


// return all the statements from cluster.candidates that fill the
// given query constraint.
var aidaStatementMatchingConstraint = function(queryConstraint, candidateList, unifInfo) {
    return filter(
	function(stmt) {
	    var stmtEntry = aidaEntry(stmt)

	    // match if the predicates are the same,
	    // and the arguments are unifiable, i.e.:
	    // either in the same equivalence class, or an unfilled variable and an ERE
	    return queryConstraint[1] == stmtEntry.predicate &&
		unifierUnifiable(queryConstraint[0], stmtEntry.subject, unifInfo) &&
		unifierUnifiable(queryConstraint[2], stmtEntry.object, unifInfo)
	    
	}, candidateList)  
}


//-------------------------------
// Proximity measures
//-----

// read the proximity between two statements off the AIDA graph
var aidaProximity = function(stmt1, stmt2) {
    if (_.has(aidaData.statementProximity, stmt1) && _.has(aidaData.statementProximity[stmt1], stmt2)) {
	// we have an entry for stmt1, and a proximity to stmt2: return that
	return aidaData.statementProximity[stmt1][stmt2]
    } else {
	// display(["proximity do not have stmts", stmt1, stmt2])	
	return 0.0
    }
}


// candidate proximity: how close is the candidate to the cluster?
// cluster: structure as above
// candidate: statement label
var candidateProximity = function(cluster, candidate) {
    return averageProximity(cluster, candidate)
}


// candidate proximity as proximity to a random cluster member
var randomMemberProximity = function(cluster, candidate) {
    var randomMember = aidaData.statements[ mySetDraw(cluster.statements)]
    return aidaProximity(randomMember, candidate)
}

// candidate proximity as average proximity:
// 1/clustersize sum_{cluster member i} proximity(i, candidate)
// when proximities are random walk probabilities, this is the probability
// of ending up at candidate when taking a one-step random walk from any cluster member.
var averageProximity = function(cluster, candidate) {
    return sum(
	map(
	    function(stmt) {
		return aidaProximity(stmt, candidate)
	    }, aidaDecodeStmtSet(cluster.statements)))  / mySetLength(cluster.statements)
}

// candidate proximity as proximity to nearest neighbor
var maxProximity = function(cluster, candidate) {
    return _.max(
	map(
	    function(stmt) {
		return aidaProximity(stmt, candidate)
	    }, aidaDecodeStmtSet(cluster.statements)
	)
    )
}

//-------------------------------
// Logical consistency
//-----

var objectUniquePredicatesHard = ["hasKBEntry", "type"];
var objectUniquePredicates = [ 'Life.Die_Agent', 'Movement.TransportPerson_Person',
			       'Manufacture.Artifact_Manufacturer', 'Movement.TransportPerson_Origin',
			       'Life.Die_Victim', 'Manufacture.Artifact_Artifact', 'Conflict.Attack_Attacker',
			       'Justice.Convict_Defendant', 'Transaction.TransferOwnership_Thing', 'GeneralAffiliation.APORA_Affiliation',
			       'Life.Die_Instrument', 'Conflict.Attack_Instrument', 'Justice.Appeal_Prosecutor',
			       'Movement.TransportArtifact_Destination', 'Contact.Broadcast_Broadcaster',
			       'Conflict.Attack_Target', 'GeneralAffiliation.Sponsorship_Sponsor', 'Movement.TransportArtifact_Origin',
			       'Justice.Appeal_Defendant', 'Justice.Convict_Adjudicator', 'Movement.TransportArtifact_Artifact',
			       'Transaction.TransferOwnership_Recipient', 'Movement.TransportArtifact_Agent',
			       'OrganizationAffiliation.EmploymentMembership_Organization', 'Transaction.TransferOwnership_Giver',
			       'Transaction.TransferOwnership_Beneficiary', 'GeneralAffiliation.Sponsorship_Entity',
			       'Movement.TransportArtifact_Instrument', 'Movement.TransportPerson_Agent', 'Movement.TransportPerson_Instrument',
			       'GeneralAffiliation.MORE_Affiliation' ];

// object uniqueness with hard constraint:
// if p is an object unique predicate, then
// if e1 p e2 and e1 p e3 then e2 = e3
var constObjectUniqueHard = function(clusterEntries, candidateEntry, cluster) {
    // test for subject uniqueness only if our candidate has a predicate that is subject-unique
    if (objectUniquePredicatesHard.indexOf(candidateEntry.predicate) > -1) {
	map(
	    function(clusterEntry) {
		// // HIER testing
		// if (candidateEntry.predicate == clusterEntry.predicate) {
		//     display(["checking equality of", candidateEntry, clusterEntry,
		// 	     unifierArgEqual(candidateEntry.subject, clusterEntry.subject, cluster.corefUnifier) &&
		// 	    candidateEntry.predicate == clusterEntry.predicate &&
		// 	     unifierArgEqual(candidateEntry.object, clusterEntry.object, cluster.corefUnifier)])
		// }
		    
		condition(!(unifierArgEqual(candidateEntry.subject, clusterEntry.subject, cluster.corefUnifier)) ||
			  candidateEntry.predicate != clusterEntry.predicate ||
			  unifierArgEqual(candidateEntry.object, clusterEntry.object, cluster.corefUnifier))
	    }, clusterEntries)
    }
}

// object uniqueness, soft constraint:
// if p is an object unique predicate, then
// if e1 p e2 and e1 p e3 then e2 = e3
// This is a soft constraint
var constObjectUnique = function(clusterEntries, candidateEntry, cluster) {
    // test for subject uniqueness only if our candidate has a predicate that is subject-unique
    if (objectUniquePredicates.indexOf(candidateEntry.predicate) > -1) {
	map(
	    function(clusterEntry) {
		// // HIER testing
		// if (candidateEntry.predicate == clusterEntry.predicate) {
		//     display(["checking conflict of", candidateEntry, clusterEntry,
		// 	     unifierArgEqual(candidateEntry.subject, clusterEntry.subject, cluster.corefUnifier) &&
		// 	     candidateEntry.predicate == clusterEntry.predicate &&
		// 	     !unifierArgEqual(candidateEntry.object, clusterEntry.object, cluster.corefUnifier)])
		// }
		    
		factor(!(unifierArgEqual(candidateEntry.subject, clusterEntry.subject, cluster.corefUnifier)) ||
		       candidateEntry.predicate != clusterEntry.predicate ||
		       unifierArgEqual(candidateEntry.object, clusterEntry.object, cluster.corefUnifier) ?
		       0 : -3)
	    }, clusterEntries)
    }
}

// do use type statements
var constUseTypes = function(cluster, candidateEntry) {
    factor(candidateEntry.predicate == "type" ? 0.1 : 0)
}

// take confidence into account
var constConfidence = function(cluster, candidateEntry) {
    factor(Math.log(candidateEntry.conf))
}

// a list of all the constraints to apply to pairs of statements.
var pairwiseConstraints = [ constObjectUniqueHard, constObjectUnique ];
// a list of all constraints to apply to the candidate statement
var unaryConstraints = [ constUseTypes, constConfidence ];

// test the logical consistency of the given cluster if candidate was to be added to it
// cluster: structure.
// candidate: statement index
var logicalConsistency = function(cluster, candidate) {
    // map statements to entries
    var candidateEntry = aidaEntry(candidate) 
    var clusterEntries = map(function(stmt) { return aidaEntry(stmt) }, cluster.statementPrototypes)

    // apply binary constraints
    map(
	function(constraintFn) {
	    constraintFn(clusterEntries, candidateEntry, cluster)
	}, pairwiseConstraints)

    // and apply unary constraints on the candidat entry
    map(
	function(constraintFn) {
	    constraintFn(cluster, candidateEntry)
	}, unaryConstraints)
}

//-------------------------------
// Functions that check and manipulate cluster objects
//-----

var clusterNoMoreQueryConstraints = function(cluster) {
    return cluster.queryConstraints.length == 0
}

var clusterNoMoreCandidateStatements = function(cluster) {
    return mySetLength(cluster.candidates) == 0
}

// compute new cluster when the candidate is added
var clusterAddCandidate = function(cluster, candidate) {
    
    // compute updated cluster components
    var newEre = myArrDiff(
	aidaCanonicalEres(
	    aidaEreInStatement(candidate),
	    cluster.corefUnifier),
	cluster.ere)
    // display(["clusterAddCandidate new ere", aidaDecodeEreArray(newEre)])

    var newStatements = aidaStatementAliases( [candidate], cluster.considered, cluster.corefUnifier)
    var updatedStatements = mySetUnion(cluster.statements, newStatements)
    var updatedConsidered = mySetUnion(cluster.considered, newStatements)
    var updatedCandidates = mySetDiff(
	mySetUnion(
	    cluster.candidates,
	    aidaCandidates(newEre, cluster.corefUnifier)), 
	updatedConsidered)
    
    var clusterUpdated = {
	// cluster members
	ere : cluster.ere.concat(newEre), 
	statements : updatedStatements,
	statementPrototypes : cluster.statementPrototypes.concat(candidate),
	// query (core facets)
	queryConstraints : cluster.queryConstraints,
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: cluster.corefUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : updatedCandidates,
	// statements for which a decision has been made
	considered : updatedConsidered,
	proximity : cluster.proximity
    }
	
    return {
	newCluster : clusterUpdated, 
	newERE : newEre,
	newStatements : [ candidate ]
    }
}

// compute new cluster when the candidate is not added
var clusterDropCandidate = function(cluster, candidate) {
    var newStatements = aidaStatementAliases( [candidate], cluster.considered, cluster.corefUnifier)

    var updatedConsidered = mySetUnion(cluster.considered, newStatements)
    var updatedCandidates = mySetDiff(cluster.candidates, newStatements)
    
    var updatedCluster = {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements,
	statementPrototypes : cluster.statementPrototypes,
	// query (core facets)
	queryConstraints : cluster.queryConstraints,
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: cluster.corefUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : updatedCandidates,
	// statements for which a decision has been made
	considered : updatedConsidered,
	proximity : cluster.proximity
    }
    
    return {
	newCluster : updatedCluster,
	newERE : [ ],
	newStatements : [ ]
    }
}

// core extension: could not fulfil query. List it as failed.
var clusterQueryFailed = function(cluster, queryConstraint) {
    var updatedCluster = {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements,
	statementPrototypes : cluster.statementPrototypes,
	// query (core facets)
	queryConstraints : myArrayMinusElt(cluster.queryConstraints, queryConstraint),
	queryFailed : cluster.queryFailed.concat([ queryConstraint ]),
	// coref
 	corefUnifier: cluster.corefUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : cluster.candidates, 
	// statements for which a decision has been made
	considered : cluster.considered,
	proximity : cluster.proximity
    }
    
    return {
	newCluster : updatedCluster, 
	newERE : [ ],
	newStatements : [ ]
    }
}

// query constraint filled by a statement we already had in the cluster.
var clusterQueryExisting = function (cluster, queryConstraint, statement) {
    // unify the first argument of the candidate with the first variable in the constraint,
    // and the second argument of the candidate with the second variable in the constraint
    var statementEntry = aidaEntry(statement)
    var updatedUnifier1 = unifierUnify(statementEntry.subject, queryConstraint[0], cluster.corefUnifier)
    var updatedUnifier = unifierUnify(statementEntry.object, queryConstraint[2], updatedUnifier1)

    var updatedCluster = {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements,
	statementPrototypes : cluster.statementPrototypes,
	// query (core facets)
	queryConstraints : myArrayMinusElt(cluster.queryConstraints, queryConstraint),
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: updatedUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : cluster.candidates, 
	// statements for which a decision has been made
	considered : cluster.considered,
	proximity : cluster.proximity
    }
    
    return {
	newCluster : updatedCluster, 
	newERE : [ ],
	newStatements : [ ]
    }
}

// found a candidate to fill a query constraint. add it
var clusterQueryAdd = function(cluster, queryConstraint, candidate) {
    
    // unify the first argument of the candidate with the first variable in the constraint,
    // and the second argument of the candidate with the second variable in the constraint
    var candidateEntry = aidaEntry(candidate)
    var updatedUnifier1 = unifierUnify(candidateEntry.subject, queryConstraint[0], cluster.corefUnifier)
    var updatedUnifier = unifierUnify(candidateEntry.object, queryConstraint[2], updatedUnifier1)

    var updatedCluster = {
	// cluster members
	ere : cluster.ere,
	statements : cluster.statements,
	statementPrototypes : cluster.statementPrototypes,
	// query (core facets)
	queryConstraints : myArrayMinusElt(cluster.queryConstraints, queryConstraint),
	queryFailed : cluster.queryFailed,
	// coref
 	corefUnifier: updatedUnifier,
	corefFn : cluster.corefFn,
	// "frontier" statements around current EREs
	candidates : cluster.candidates, 
	// statements for which a decision has been made
	considered : cluster.considered,
	proximity : cluster.proximity
    }
      // display(["updated queryAdd yields", updated2.query])
    
    // the rest is as in clusterAddCandidate, so use that
    return clusterAddCandidate( updatedCluster, candidate)
}


//-------------------------------
// Handling coreference
//-----

// throw a coin to see whether this coref statement should be a  member of the cluster
var corefIsMember = function(corefFn, corefStmt) {
    var corefGroup = aidaData.theGraph[corefStmt].cluster
    var member = aidaData.theGraph[corefStmt].clusterMember
    var confidence = aidaData.theGraph[corefStmt].conf

    // coref group not in the cluster yet, and we've sampled that this ere is in the group
    return (corefFn(corefGroup, member, confidence))   
}

// given a coref function, return the list of coref statements
// that are set to true by the coref function
var corefStmtsTrueBy = function(corefFn) {
    return filter(
	function(label) {
	    return (aidaData.theGraph[label].type == "ClusterMembership" &&
		    corefIsMember(corefFn, label))
	}, _.keys(aidaData.theGraph))
}

// for all coref statements, decide whether they are true in this sample.
// all we know of the sample is the coref function.
var corefDo = function(corefFn) {
    // returns the new unifier
    
    // decide coreference for all groups
    var corefStmts = corefStmtsTrueBy(corefFn)

    var corefGroups = myArrUnique(
	map(
	    function(corefStmt) {
		return aidaData.theGraph[corefStmt].cluster
	    }, corefStmts)
    )

    var newUnifier = reduce(
	function(corefStmt, acc) {
	    var clMember = aidaData.theGraph[corefStmt].clusterMember
	    var corefGroup = aidaData.theGraph[corefStmt].cluster
	    var clPrototype = aidaData.theGraph[ corefGroup ].prototype

	    return unifierUnify(clMember, clPrototype, acc)
	}, unifierInitial(), corefStmts)

    return newUnifier
}

// determine EREs that are not in the cluster yet but that are
// in the same equivalence groups as the eres in 'eres'
var corefAdditionalEres = function(cluster, eres) {
    return filter(
	function(ere) {
	    return aidaIsEre(ere) &&
		cluster.ere.indexOf(ere) == -1 &&
		any(
		    function(ere2) {
			unifierEquals(ere, ere2, cluster.corefUnifier)
		    }, eres)
	}, _.keys(aidaData.theGraph))
}

//-------------------------------
// Extending the cluster
//-----

// extend the cluster once, either by choosing a core constraint to fill, if there is one,
// or by choosing a statement that we haven't considered yet that is adjacent to one
// of the cluster's EREs
var extendClusterOnce = function(cluster, thresholdParameters) {
    // if there are no query constraints, add a candidate statement from the frontier.
    if (clusterNoMoreQueryConstraints(cluster)) {
	return extendClusterOnceByCandidateStatement(cluster, thresholdParameters)
    } else {
	// we do still have core constraints to do
	return extendClusterOnceByQueryConstraint(cluster, thresholdParameters)
    }
}

// extend the cluster once by choosing a core constraint to fill
// this returns a structure with entries
// newCluster: updated cluster
// newERE: ERE indices added to the frontier of the cluster
// newStatements: statements added to the cluster
var extendClusterOnceByQueryConstraint = function(cluster, thresholdParameters) {
    if (clusterNoMoreQueryConstraints(cluster)) {
	// nothing to do after all
	return {
	    newCluster : cluster,
	    newERE : [ ],
	    newStatements : [ ]
	}
    } else {
	// query constraints remaining. randomly choose one of them.
	var queryConstraint = uniformDraw(cluster.queryConstraints)
	// display(["considering query constraint", queryConstraint])

	// constraint has the form ?entry1 Rel ?entry2
	var arg1 = queryConstraint[0]
	var arg2 = queryConstraint[2]

	if (unifierVarUnbound(arg1, cluster.corefUnifier) && unifierVarUnbound(arg2, cluster.corefUnifier)) {
	    // we cannot possibly fill this constraint at this point.
	    // don't fill it, and give this sample a penalty
	    // display(["two open variables, queryConstraint cannot be filled", queryConstraint])
	    factor(-5)
	    return clusterQueryFailed(cluster, queryConstraint)
	} else {
	    // check if any statement we have already fills the constraint
	    var statementsMatching = aidaStatementMatchingConstraint(queryConstraint, cluster.statementPrototypes, cluster.corefUnifier)
	    // display(["aidaSMC stmt calling with", queryConstraint, cluster.statementPrototypes, "result", statementsMatching])
	    
	    if (statementsMatching.length > 0) {
		// we have a match.
		// display(["query constraint already filled", queryConstraint, statementsMatching])
		var statement = uniformDraw(statementsMatching)
		return clusterQueryExisting(cluster, queryConstraint, statement)
		
	    } else {
		// no match in statements. so look in candidates
		var candidates = aidaStatementMatchingConstraint(queryConstraint, aidaDecodeStmtSet(cluster.candidates), cluster.corefUnifier)
		// display(["aidaSMC cand calling with", queryConstraint, aidaDecodeStmtSet(cluster.candidates), "result", candidates])
		// display(["queryConstraint candidates", candidates])
		if (candidates.length == 0) {
		    // no match for this constraint. just don't fill it then,
		    // and give this sample a penality
		    // display(["queryConstraint cannot be filled, no candidates", queryConstraint])
		    factor(-5)
		    return clusterQueryFailed(cluster, queryConstraint)
		} else {
		    var candidate = uniformDraw(candidates)
		    // display(["filling query constraint with candidate", candidate])
		    return clusterQueryAdd(cluster, queryConstraint, candidate)
		}
	    }
	}
    }
}

// extend the cluster once by choosing a statement from the candidate list
// this returns a structure with entries
// newCluster: updated cluster
// newERE: EREs added to the frontier of the cluster
// newStatements: statements added to the cluster
var extendClusterOnceByCandidateStatement = function(cluster, thresholdParameters) {
    if (clusterNoMoreCandidateStatements(cluster)) {
	// nothing to do after all
	return {
	    newCluster : cluster,
	    newERE : [ ],
	    newStatements : [ ]
	}
    } else {
	// consider a candidate
	// draw from the decoded version of the set of candidates
	var candidate = aidaData.statements[ mySetDraw(cluster.candidates) ]
	var thisCandidateProximity = candidateProximity(cluster, candidate)
	    
	// choose a threshold for it
	var tau = gamma( thresholdParameters )

	// choose whether it is a member
	var isMember = flip(aidaQuery.memberProb)
	// var testMargin = (isMember ?
	//		  ( tau > thisCandidateProximity ? thisCandidateProximity - tau : 0)
	//		  :
	//		  (tau < thisCandidateProximity ? tau - thisCandidateProximity : 0))
	//
	// display(["tau", testMargin, tau, thisCandidateProximity, (isMember && thisCandidateProximity > tau) || (!isMember && thisCandidateProximity < tau)])

	var updatedCluster = thisCandidateProximity == 0 ? cluster :	
	    {
		// cluster members
		ere : cluster.ere,
		statements : cluster.statements,
		statementPrototypes : cluster.statementPrototypes,
		// query (core facets)
		queryConstraints : cluster.queryConstraints, 
		queryFailed : cluster.queryFailed,
		// coref
 		corefUnifier: cluster.corefUnifier, 
		corefFn : cluster.corefFn,
		// "frontier" statements around current EREs
		candidates : cluster.candidates, 
		// statements for which a decision has been made
		considered : cluster.considered,
		proximity : cluster.proximity.concat( thisCandidateProximity)
	    }

    	// The candidate needs to be on the right side of threshold tau
    	if (isMember) {
	    factor( tau > thisCandidateProximity ? thisCandidateProximity - tau : 0)
	    // turned hard condition into factor because we keep having trouble with setting the threshold well
    	    // condition( candidateProximity(cluster, candidate) > tau)

    	    return clusterAddCandidate(updatedCluster, candidate)
	    
    	} else {
	    factor( tau < thisCandidateProximity ? tau - thisCandidateProximity : 0)
	    // again, not hard condition for now because of high sensitivity to threshold
    	    // condition( candidateProximity( cluster, candidate) < tau)
	    
    	    return clusterDropCandidate(updatedCluster, candidate)
    	}
    }
}



//-------------------------------
// Inference
//-----

// Recursive sample for the particle filter
var recursivelyExtendCluster = function(cluster, thresholdParameters) {

    if (clusterNoMoreQueryConstraints(cluster) && clusterNoMoreCandidateStatements(cluster)) {
	// nothing more to add to this cluster, end recursion
	// display(["done with cluster"])
	return cluster;
    } else {
	// try to do one step of additions to the cluster
	// this returns a structure with entries
	// newCluster: updated cluster
	// newERE: EREs added to the frontier of the cluster
	// newStatements: statements added to the cluster
	var result = extendClusterOnce(cluster, thresholdParameters)
	
	// check logical consistency constraints for the new statements
	map(
	    function(candidate) {
		logicalConsistency(result.newCluster, candidate)
	    }, result.newStatements
	)

	// and repeat
	return recursivelyExtendCluster( result.newCluster, thresholdParameters)
    }
}
    


var model = function() {
    // cluster seed:
    // draw from entry points
    var clusterSeed =  uniformDraw(aidaQuery["entrypoints"])
    // display(["cluster seed", clusterSeed])

    // coreference resolution: we use a mem'ed function
    // to remember which EREs belong to which coref group
    var corefFn = mem(function(corefGroup, ere, confidence) {
	return flip(confidence)
    })

    // compute a unifier based on this coref function
    var unifier = corefDo(corefFn)

    // EREs to store in the cluster: take only the unifiers,
    // rather than all the coref mentions
    var initialEres = aidaCanonicalEres(clusterSeed.ere, unifier)
    // display(["initial EREs", aidaDecodeEreArray(initialEres)])

    // compute representation of included statements, with duplicates
    // var statementsNoAliases = aidaStmtSetUpdate(mySetEmpty(aidaData.statements.length), clusterSeed.statements)
    // display(["initial statements without aliases", aidaDecodeStmtSet(statementsNoAliases), mySetLength(statementsNoAliases)])
    var initialStatements = aidaStatementAliases(clusterSeed.statements, mySetEmpty(aidaData.statements.length), unifier)
    // display(["initial statements", aidaDecodeStmtSet(initialStatements)])
    
    // compute candidates
    var initialCandidates = mySetDiff(aidaCandidates(initialEres, unifier),
			       initialStatements)
    // display(["initial candidates", aidaDecodeStmtSet(initialCandidates)])
    
    // assemble initial cluster    
    var clusterInitial = {
	// cluster members
	ere : initialEres,
	statements : initialStatements,
	statementPrototypes : clusterSeed.statements,
	// query (core facets)
	queryConstraints : clusterSeed.queryConstraints, 
	queryFailed : [ ],
	// coref
 	corefUnifier: unifier, 
	corefFn : corefFn,
	// "frontier" statements around current EREs
	candidates : initialCandidates, 
	// statements for which a decision has been made
	considered : initialStatements,
	proximity : [ ]
    }
    
						       
    // now do the work
    var clusterFinal = recursivelyExtendCluster(clusterInitial, aidaQuery.parameters)

    display(["sample avg proximity", listMean(clusterFinal.proximity), "stdev", listStdev(clusterFinal.proximity)])

    // and report on results
    return clusterFinal.proximity
}
			  

var Experiment = function () {
    return Infer( { method : "SMC", particles : 5 }, model)
}

//-------------------------------
var result = Experiment()

"proximity exploration done."
